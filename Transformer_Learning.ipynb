{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qTliUCPn1yz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BjLDh3d4oR4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å¯¼å…¥ torch åº“ï¼Œè¿™æ˜¯ PyTorch çš„æ ¸å¿ƒåº“ï¼Œæˆ‘ä»¬å°†ç”¨å®ƒæ¥æ„å»ºç¥ç»ç½‘ç»œçš„æ‰€æœ‰éƒ¨åˆ†ã€‚\n",
        "import torch\n",
        "# å¯¼å…¥ torch.nn æ¨¡å—ï¼Œå®ƒåŒ…å«äº†æ‰€æœ‰æ„å»ºç¥ç»ç½‘ç»œæ‰€éœ€çš„ç±»å’Œå‡½æ•°ï¼Œæ¯”å¦‚çº¿æ€§å±‚ã€Dropoutå±‚ç­‰ã€‚\n",
        "# æˆ‘ä»¬ç»™å®ƒä¸€ä¸ªåˆ«å nnï¼Œè¿™æ˜¯ PyTorch çš„ä¸€ä¸ªå¸¸ç”¨çº¦å®šã€‚\n",
        "import torch.nn as nn\n",
        "# å¯¼å…¥ math åº“ï¼Œè¿™æ˜¯ä¸€ä¸ª Python çš„æ ‡å‡†æ•°å­¦åº“ï¼Œæˆ‘ä»¬å°†ç”¨å®ƒæ¥è¿›è¡Œä¸€äº›æ•°å­¦è®¡ç®—ï¼Œæ¯”å¦‚ sin, cos, log ç­‰ã€‚\n",
        "import math\n",
        "\n",
        "# è¿™è¡Œä»£ç æ˜¯ç”¨æ¥è®¾ç½® PyTorch åœ¨å“ªä¸ªè®¾å¤‡ä¸Šè¿è¡Œã€‚\n",
        "# torch.cuda.is_available() ä¼šæ£€æŸ¥ä½ çš„ç¯å¢ƒæ˜¯å¦æ”¯æŒ NVIDIA çš„ CUDAï¼Œä¹Ÿå°±æ˜¯æ˜¯å¦èƒ½ç”¨ GPUã€‚\n",
        "# å¦‚æœå¯ä»¥ç”¨ GPUï¼Œdevice å°±è¢«è®¾ç½®ä¸º \"cuda\"ï¼›å¦åˆ™ï¼Œå°±ç”¨ \"cpu\"ã€‚\n",
        "# åœ¨æˆ‘ä»¬åˆšåˆšè®¾ç½®å¥½çš„ Colab ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šé€‰æ‹© \"cuda\"ã€‚\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# æ‰“å°ä¸€ä¸‹æˆ‘ä»¬å½“å‰ä½¿ç”¨çš„è®¾å¤‡ï¼Œç¡®è®¤ä¸€ä¸‹ GPU æ˜¯å¦è®¾ç½®æˆåŠŸã€‚\n",
        "print(f\"å½“å‰ä½¿ç”¨çš„è®¾å¤‡æ˜¯: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH-nMiFboR62",
        "outputId": "3a767db1-055c-4bd8-eb0b-b884630148a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å½“å‰ä½¿ç”¨çš„è®¾å¤‡æ˜¯: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pIM3SlSYoR8z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ã€ä¿®æ­£åçš„ PositionalEncoding ç±»ã€‘\n",
        "# å®šä¹‰ä¸€ä¸ªåä¸º PositionalEncoding çš„ç±»ã€‚\n",
        "# å®ƒç»§æ‰¿è‡ª nn.Moduleï¼Œè¿™æ˜¯ PyTorch ä¸­æ‰€æœ‰ç¥ç»ç½‘ç»œæ¨¡å—çš„åŸºç±»ã€‚\n",
        "# ç»§æ‰¿å®ƒæ„å‘³ç€æˆ‘ä»¬çš„ PositionalEncoding ç±»ä¼šè‡ªåŠ¨è·å¾—å¾ˆå¤šæœ‰ç”¨çš„åŠŸèƒ½ï¼ˆæ¯”å¦‚å‚æ•°ç®¡ç†ï¼‰ã€‚\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    # è¿™æ˜¯ç±»çš„æ„é€ å‡½æ•°ï¼ˆinitializerï¼‰ï¼Œå½“æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª PositionalEncoding çš„å®ä¾‹æ—¶ï¼Œè¿™ä¸ªå‡½æ•°ä¼šè¢«è‡ªåŠ¨è°ƒç”¨ã€‚\n",
        "    # å®ƒæ¥æ”¶ä¸‰ä¸ªå‚æ•°ï¼š\n",
        "    # d_model: è¯åµŒå…¥çš„ç»´åº¦ï¼ˆæ¯”å¦‚ 512ï¼‰ã€‚ä½ç½®ç¼–ç çš„ç»´åº¦éœ€è¦å’Œè¯åµŒå…¥ç»´åº¦ç›¸åŒï¼Œè¿™æ ·å®ƒä»¬æ‰èƒ½ç›¸åŠ ã€‚\n",
        "    # dropout: ä¸€ä¸ªä»‹äº 0 å’Œ 1 ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œä»£è¡¨åœ¨è®­ç»ƒæ—¶éšæœºâ€œä¸¢å¼ƒâ€ä¸€éƒ¨åˆ†ç¥ç»å…ƒçš„æ¯”ä¾‹ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚é»˜è®¤ä¸º 0.1ã€‚\n",
        "    # max_len: æ¨¡å‹èƒ½å¤„ç†çš„å¥å­çš„æœ€å¤§é•¿åº¦ï¼ˆæ¯”å¦‚ 5000ï¼‰ã€‚æˆ‘ä»¬ä¼šé¢„å…ˆè®¡ç®—å¥½è¿™ä¹ˆé•¿æ‰€æœ‰ä½ç½®çš„ä½ç½®ç¼–ç ã€‚\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        # super().__init__() æ˜¯ä¸€ä¸ªå¿…é¡»çš„æ­¥éª¤ï¼Œå®ƒè°ƒç”¨äº†çˆ¶ç±» nn.Module çš„æ„é€ å‡½æ•°ï¼Œä»¥æ­£ç¡®åœ°åˆå§‹åŒ–åŸºç±»ã€‚\n",
        "        super().__init__()\n",
        "\n",
        "        # å®šä¹‰ä¸€ä¸ª Dropout å±‚ã€‚nn.Dropout æ˜¯ PyTorch æä¾›çš„ç°æˆçš„å±‚ã€‚\n",
        "        # æˆ‘ä»¬å°†æŠŠå®ƒåº”ç”¨åœ¨ä½ç½®ç¼–ç ä¸è¯åµŒå…¥ç›¸åŠ ä¹‹åçš„ç»“æœä¸Šã€‚\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º (max_len, d_model) çš„å…¨é›¶å¼ é‡ï¼ˆtensorï¼‰ï¼Œç”¨æ¥å­˜æ”¾æˆ‘ä»¬çš„ä½ç½®ç¼–ç ã€‚\n",
        "        # å¼ é‡æ˜¯ PyTorch ä¸­æœ€åŸºæœ¬çš„æ•°æ®ç»“æ„ï¼Œå¯ä»¥çœ‹ä½œæ˜¯å¤šç»´æ•°ç»„ã€‚\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º (max_len, 1) çš„å¼ é‡ï¼Œä»£è¡¨å¥å­çš„ä½ç½®ç´¢å¼•ï¼Œå³ [0, 1, 2, ..., max_len-1]ã€‚\n",
        "        # torch.arange(0, max_len, dtype=torch.float) ä¼šç”Ÿæˆä¸€ä¸ªä¸€ç»´å¼ é‡ [0., 1., ..., max_len-1.]ã€‚\n",
        "        # .unsqueeze(1) ä¼šåœ¨ç¬¬ 1 ç»´ï¼ˆä»0å¼€å§‹æ•°ï¼‰å¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œå°†å½¢çŠ¶ä» [max_len] å˜ä¸º [max_len, 1]ã€‚\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # è¿™æ˜¯è®¡ç®—ä½ç½®ç¼–ç å…¬å¼ä¸­åˆ†æ¯çš„éƒ¨åˆ†ï¼š10000^(2i / d_model)ã€‚\n",
        "        # torch.arange(0, d_model, 2).float() ç”Ÿæˆ [0, 2, 4, ..., d_model-2]ï¼Œä»£è¡¨å…¬å¼ä¸­çš„ 2iã€‚\n",
        "        # æ•´ä¸ªè¡¨è¾¾å¼è®¡ç®—å‡ºäº†ä¸€ä¸ªåŒ…å« d_model/2 ä¸ªå€¼çš„å¼ é‡ï¼Œç”¨äºåç»­å’Œ position ç›¸ä¹˜ã€‚\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # ä½¿ç”¨åˆ‡ç‰‡æ“ä½œå’Œå¹¿æ’­æœºåˆ¶ï¼ŒåŒæ—¶è®¡ç®—æ‰€æœ‰å¶æ•°ç»´åº¦ï¼ˆ0, 2, 4, ...ï¼‰çš„ä½ç½®ç¼–ç å€¼ã€‚\n",
        "        # pe[:, 0::2] è¡¨ç¤ºé€‰å–æ‰€æœ‰è¡Œï¼Œä½†åªé€‰å–ä»ç¬¬ 0 åˆ—å¼€å§‹ï¼Œæ­¥é•¿ä¸º 2 çš„åˆ—ï¼ˆå³å¶æ•°åˆ—ï¼‰ã€‚\n",
        "        # position * div_term ä¼šåˆ©ç”¨å¹¿æ’­ï¼ˆbroadcastingï¼‰æœºåˆ¶ï¼Œ(max_len, 1) çš„ position ä¼šå’Œ (d_model/2) çš„ div_term ç›¸ä¹˜ï¼Œ\n",
        "        # å¾—åˆ°ä¸€ä¸ª (max_len, d_model/2) çš„ç»“æœã€‚\n",
        "        # æœ€åç”¨ torch.sin è®¡ç®—æ­£å¼¦å€¼ã€‚\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "        # åŒç†ï¼Œè®¡ç®—æ‰€æœ‰å¥‡æ•°ç»´åº¦ï¼ˆ1, 3, 5, ...ï¼‰çš„ä½ç½®ç¼–ç å€¼ã€‚\n",
        "        # pe[:, 1::2] è¡¨ç¤ºé€‰å–æ‰€æœ‰è¡Œï¼Œä½†åªé€‰å–ä»ç¬¬ 1 åˆ—å¼€å§‹ï¼Œæ­¥é•¿ä¸º 2 çš„åˆ—ï¼ˆå³å¥‡æ•°åˆ—ï¼‰ã€‚\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # ã€ä¿®æ­£1ã€‘: è°ƒæ•´ pe çš„å½¢çŠ¶ä»¥åŒ¹é… (batch_size, seq_len, d_model) çš„è¾“å…¥æ ¼å¼ã€‚\n",
        "        # æˆ‘ä»¬ä¹‹å‰çš„ä»£ç å¯¹ pe è¿›è¡Œäº†å¤æ‚ä¸”é”™è¯¯çš„å˜å½¢ã€‚\n",
        "        # æ­£ç¡®çš„åšæ³•æ˜¯ï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨æœ€å‰é¢å¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œä½œä¸ºâ€œæ‰¹æ¬¡â€ç»´åº¦ã€‚\n",
        "        # è¿™æ · pe çš„å½¢çŠ¶ä» (max_len, d_model) å˜ä¸º (1, max_len, d_model)ã€‚\n",
        "        # è¿™ä¸ªå½¢çŠ¶å¯ä»¥é€šè¿‡å¹¿æ’­ï¼ˆbroadcastingï¼‰æœºåˆ¶ï¼Œè½»æ¾åœ°ä¸ (batch_size, seq_len, d_model) çš„è¾“å…¥ç›¸åŠ ã€‚\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # self.register_buffer('pe', pe) æ˜¯ä¸€ä¸ªé‡è¦çš„æ–¹æ³•ã€‚\n",
        "        # å®ƒå°† pe è¿™ä¸ªå¼ é‡æ³¨å†Œä¸ºæ¨¡å‹çš„â€œç¼“å†²åŒºâ€(buffer)ã€‚\n",
        "        # è¿™æ„å‘³ç€ pe æ˜¯æ¨¡å‹çŠ¶æ€çš„ä¸€éƒ¨åˆ†ï¼ˆä¼šå’Œæ¨¡å‹ä¸€èµ·ä¿å­˜ã€åŠ è½½ï¼Œä¸€èµ·è¢«ç§»åŠ¨åˆ° GPUï¼‰ï¼Œ\n",
        "        # ä½†å®ƒä¸æ˜¯æ¨¡å‹çš„å‚æ•°ï¼ˆparametersï¼‰ï¼Œæ‰€ä»¥åœ¨æ¨¡å‹è®­ç»ƒæ—¶ï¼Œå®ƒçš„å€¼ä¸ä¼šè¢«æ¢¯åº¦ä¸‹é™æ›´æ–°ã€‚\n",
        "        # è¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼Œå› ä¸ºä½ç½®ç¼–ç æ˜¯å›ºå®šçš„ï¼Œä¸éœ€è¦å­¦ä¹ ã€‚\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    # forward æ–¹æ³•å®šä¹‰äº†å½“æ•°æ®é€šè¿‡è¿™ä¸ªæ¨¡å—æ—¶ï¼Œéœ€è¦æ‰§è¡Œçš„è®¡ç®—ã€‚\n",
        "    # x: è¾“å…¥çš„å¼ é‡ï¼Œä»£è¡¨è¯åµŒå…¥ã€‚å®ƒçš„å½¢çŠ¶æ˜¯ (batch_size, seq_len, d_model)ã€‚\n",
        "    def forward(self, x):\n",
        "        # ã€ä¿®æ­£2ã€‘: ä¿®æ­£åˆ‡ç‰‡æ“ä½œï¼Œå¹¶æ­£ç¡®åœ°åŠ ä¸Šä½ç½®ç¼–ç ã€‚\n",
        "        # x.size(1) ç°åœ¨æ­£ç¡®åœ°ä»£è¡¨äº†åºåˆ—é•¿åº¦ seq_lenã€‚\n",
        "        # self.pe[:, :x.size(1), :] çš„æ„æ€æ˜¯ï¼š\n",
        "        # - ç¬¬ä¸€ä¸ª ':' è¡¨ç¤ºå–æ‰¹æ¬¡ç»´åº¦çš„æ‰€æœ‰æ•°æ®ï¼ˆæˆ‘ä»¬åªæœ‰ä¸€ä¸ªï¼Œå°±æ˜¯é‚£ä¸ª 1ï¼‰ã€‚\n",
        "        # - ':x.size(1)' è¡¨ç¤ºå–åºåˆ—é•¿åº¦ç»´åº¦çš„å‰ seq_len ä¸ªä½ç½®ç¼–ç ã€‚\n",
        "        # - ç¬¬äºŒä¸ª ':' è¡¨ç¤ºå– d_model ç»´åº¦çš„æ‰€æœ‰æ•°æ®ã€‚\n",
        "        # æœ€ç»ˆåˆ‡ç‰‡å‡ºæ¥çš„ pe å½¢çŠ¶æ˜¯ (1, seq_len, d_model)ã€‚\n",
        "        # å½“å®ƒå’Œå½¢çŠ¶ä¸º (batch_size, seq_len, d_model) çš„ x ç›¸åŠ æ—¶ï¼ŒPyTorch ä¼šè‡ªåŠ¨å°† pe çš„ç¬¬ä¸€ç»´å¤åˆ¶ batch_size æ¬¡ï¼Œå®Œæˆç›¸åŠ ã€‚\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "\n",
        "        # å°†ç›¸åŠ åçš„ç»“æœé€šè¿‡ dropout å±‚ï¼Œç„¶åè¿”å›ã€‚\n",
        "        return self.dropout(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "yQz8GDycoR_D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1n-3xF1oSBC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å®šä¹‰ä¸€ä¸ªåä¸º MultiHeadAttention çš„ç±»ï¼Œå®ƒåŒæ ·ç»§æ‰¿è‡ª nn.Moduleã€‚\n",
        "# è¿™æ˜¯æˆ‘ä»¬ Transformer æ¨¡å‹çš„æ ¸å¿ƒå¼•æ“ã€‚\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    # ç±»çš„æ„é€ å‡½æ•°ã€‚\n",
        "    # d_model: è¯åµŒå…¥çš„ç»´åº¦ï¼Œå®ƒå¿…é¡»èƒ½è¢«å¤´çš„æ•°é‡æ•´é™¤ã€‚\n",
        "    # num_heads: æ³¨æ„åŠ›â€œå¤´â€çš„æ•°é‡ã€‚å¤šå¤´å…è®¸æ¨¡å‹ä»ä¸åŒè§’åº¦å…³æ³¨ä¿¡æ¯ã€‚\n",
        "    # dropout: Dropout çš„æ¯”ä¾‹ï¼Œé»˜è®¤ä¸º 0.1ã€‚\n",
        "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
        "        # å¿…é¡»çš„æ­¥éª¤ï¼šè°ƒç”¨çˆ¶ç±» nn.Module çš„æ„é€ å‡½æ•°ã€‚\n",
        "        super().__init__()\n",
        "\n",
        "        # ä½¿ç”¨ assert è¯­å¥è¿›è¡Œä¸€ä¸ªå¥å…¨æ€§æ£€æŸ¥ã€‚\n",
        "        # assert æ˜¯ä¸€ä¸ªæ–­è¨€ï¼Œå¦‚æœåé¢çš„æ¡ä»¶ä¸º Falseï¼Œç¨‹åºå°±ä¼šåœ¨è¿™é‡ŒæŠ¥é”™ã€‚\n",
        "        # è¿™é‡Œæˆ‘ä»¬ç¡®ä¿ d_model å¿…é¡»èƒ½å¤Ÿè¢« num_heads æ•´é™¤ã€‚\n",
        "        # æ¯”å¦‚ï¼Œå¦‚æœ d_model=512, num_heads=8ï¼Œé‚£ä¹ˆ 512 % 8 == 0ï¼Œæ¡ä»¶ä¸º Trueï¼Œç¨‹åºç»§ç»­ã€‚\n",
        "        # å¦‚æœ d_model=512, num_heads=7ï¼Œæ¡ä»¶ä¸º Falseï¼Œç¨‹åºä¼šæŠ¥é”™ï¼Œæç¤ºæˆ‘ä»¬å‚æ•°è®¾ç½®æœ‰é—®é¢˜ã€‚\n",
        "        assert d_model % num_heads == 0\n",
        "\n",
        "        # åˆå§‹åŒ–å®ä¾‹å˜é‡ã€‚\n",
        "        self.d_model = d_model      # æ¨¡å‹çš„æ€»ç»´åº¦\n",
        "        self.num_heads = num_heads  # æ³¨æ„åŠ›å¤´çš„æ•°é‡\n",
        "        self.d_k = d_model // num_heads # æ¯ä¸ªå¤´çš„ç»´åº¦ã€‚// æ˜¯æ•´æ•°é™¤æ³•ã€‚ä¾‹å¦‚ 512 // 8 = 64ã€‚\n",
        "\n",
        "        # å®šä¹‰å››ä¸ªçº¿æ€§å±‚ï¼ˆLinear Layerï¼‰ï¼Œå®ƒä»¬æœ¬è´¨ä¸Šå°±æ˜¯å…¨è¿æ¥å±‚ï¼Œç”¨æ¥è¿›è¡Œçº¿æ€§å˜æ¢ï¼ˆçŸ©é˜µä¹˜æ³•ï¼‰ã€‚\n",
        "        # nn.Linear(input_features, output_features)\n",
        "        # è¿™é‡Œçš„å››ä¸ªçº¿æ€§å±‚å°±å¯¹åº”æˆ‘ä»¬ç†è®ºä¸­å­¦åˆ°çš„ Wq, Wk, Wv, Wo æƒé‡çŸ©é˜µã€‚\n",
        "        self.query = nn.Linear(d_model, d_model) # ç”¨äºç”Ÿæˆ Query å‘é‡\n",
        "        self.key = nn.Linear(d_model, d_model)   # ç”¨äºç”Ÿæˆ Key å‘é‡\n",
        "        self.value = nn.Linear(d_model, d_model) # ç”¨äºç”Ÿæˆ Value å‘é‡\n",
        "\n",
        "        # è¿™æ˜¯æœ€åä¸€ä¸ªçº¿æ€§å±‚ï¼Œå¯¹åº” Wo çŸ©é˜µã€‚å®ƒæ¥æ”¶æ‹¼æ¥åçš„å¤šå¤´æ³¨æ„åŠ›ç»“æœï¼Œå¹¶è¾“å‡ºæœ€ç»ˆçš„ d_model ç»´åº¦å‘é‡ã€‚\n",
        "        self.fc_out = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # å®šä¹‰ä¸€ä¸ª Dropout å±‚ã€‚\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # forward æ–¹æ³•å®šä¹‰äº†å‰å‘ä¼ æ’­çš„é€»è¾‘ã€‚\n",
        "    # query, key, value: è¿™ä¸‰ä¸ªæ˜¯è¾“å…¥çš„ Q, K, V å‘é‡ã€‚\n",
        "    #   - åœ¨ Encoder çš„è‡ªæ³¨æ„åŠ›å±‚ä¸­ï¼Œè¿™ä¸‰ä¸ªè¾“å…¥æ˜¯å®Œå…¨ç›¸åŒçš„ï¼ˆéƒ½ç­‰äºä¸Šä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚\n",
        "    #   - åœ¨ Decoder çš„ Encoder-Decoder æ³¨æ„åŠ›å±‚ä¸­ï¼ŒQuery æ¥è‡ª Decoderï¼Œè€Œ Key å’Œ Value æ¥è‡ª Encoder çš„è¾“å‡ºã€‚\n",
        "    # mask: æ©ç ï¼Œç”¨äºå‘Šè¯‰æ¨¡å‹å“ªäº›éƒ¨åˆ†æ˜¯å¡«å……ï¼ˆpaddingï¼‰çš„ï¼Œä¸éœ€è¦å…³æ³¨ã€‚æˆ–è€…åœ¨ Decoder ä¸­ç”¨äºé˜²æ­¢çœ‹åˆ°æœªæ¥çš„è¯ã€‚\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        # è·å– batch_sizeï¼ˆæ‰¹æ¬¡å¤§å°ï¼‰ï¼Œä¹Ÿå°±æ˜¯ä¸€æ¬¡æ€§å¤„ç†å¤šå°‘ä¸ªå¥å­ã€‚\n",
        "        # query.shape æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œä¾‹å¦‚ (32, 100, 512)ï¼Œä»£è¡¨ (batch_size, sequence_length, d_model)ã€‚\n",
        "        # query.shape[0] å°±æ˜¯è·å–ç¬¬ä¸€ä¸ªç»´åº¦çš„å¤§å°ï¼Œå³ 32ã€‚\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # 1. å°†è¾“å…¥çš„ query, key, value é€šè¿‡æˆ‘ä»¬å®šä¹‰çš„çº¿æ€§å±‚ï¼Œè¿›è¡Œçº¿æ€§å˜æ¢ã€‚\n",
        "        #    è¿™æ­¥ç›¸å½“äºä¹˜ä»¥ Wq, Wk, Wv çŸ©é˜µã€‚\n",
        "        #    è¾“å…¥å½¢çŠ¶: (batch_size, seq_len, d_model)\n",
        "        #    è¾“å‡ºå½¢çŠ¶: (batch_size, seq_len, d_model)\n",
        "        Q = self.query(query)\n",
        "        K = self.key(key)\n",
        "        V = self.value(value)\n",
        "\n",
        "        # 2. å°†å˜æ¢åçš„ Q, K, V è¿›è¡Œå½¢çŠ¶é‡å¡‘ï¼ˆreshapeï¼‰ï¼Œä»¥ä¾¿è¿›è¡Œå¤šå¤´æ³¨æ„åŠ›çš„è®¡ç®—ã€‚\n",
        "        #    æˆ‘ä»¬éœ€è¦æŠŠ d_model è¿™ä¸ªç»´åº¦æ‹†åˆ†æˆ num_heads å’Œ d_k ä¸¤ä¸ªç»´åº¦ã€‚\n",
        "        #    .view() å‡½æ•°ç”¨äºæ”¹å˜å¼ é‡çš„å½¢çŠ¶ã€‚\n",
        "        #    åŸå§‹å½¢çŠ¶: (batch_size, seq_len, d_model)\n",
        "        #    ç›®æ ‡å½¢çŠ¶: (batch_size, seq_len, num_heads, d_k)\n",
        "        #    .transpose(1, 2) ç”¨äºäº¤æ¢ç»´åº¦ 1 å’Œ 2ã€‚\n",
        "        #    æœ€ç»ˆå½¢çŠ¶: (batch_size, num_heads, seq_len, d_k)\n",
        "        #    è¿™ä¹ˆåšæ˜¯ä¸ºäº†è®©æ¯ä¸ªå¤´éƒ½èƒ½ç‹¬ç«‹åœ°å¤„ç†æ•´ä¸ªåºåˆ—ã€‚\n",
        "        Q = Q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = K.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = V.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # 3. è®¡ç®—æ³¨æ„åŠ›å¾—åˆ†ã€‚è¿™å¯¹åº”äºæˆ‘ä»¬ç†è®ºä¸­çš„å…¬å¼ (Q * K^T) / sqrt(d_k)\n",
        "        #    torch.matmul() æ‰§è¡ŒçŸ©é˜µä¹˜æ³•ã€‚\n",
        "        #    K.transpose(-2, -1) å°† K çš„æœ€åä¸¤ä¸ªç»´åº¦è¿›è¡Œè½¬ç½®ã€‚\n",
        "        #    K çš„å½¢çŠ¶æ˜¯ (batch_size, num_heads, seq_len_k, d_k)\n",
        "        #    è½¬ç½®å K^T çš„å½¢çŠ¶æ˜¯ (batch_size, num_heads, d_k, seq_len_k)\n",
        "        #    Q * K^T çš„ç»“æœ `energy` çš„å½¢çŠ¶æ˜¯ (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        energy = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # 4. åº”ç”¨æ©ç ï¼ˆmaskï¼‰ã€‚\n",
        "        #    å¦‚æœä¼ å…¥äº† maskï¼Œå°±éœ€è¦å°† mask ä¸­å€¼ä¸º 0 çš„ä½ç½®ï¼ˆé€šå¸¸æ˜¯ padding çš„ä½ç½®ï¼‰åœ¨ energy ä¸­å¯¹åº”çš„å€¼è®¾ä¸ºä¸€ä¸ªéå¸¸å°çš„è´Ÿæ•°ã€‚\n",
        "        #    è¿™æ ·ï¼Œåœ¨ä¸‹ä¸€æ­¥è¿›è¡Œ softmax æ—¶ï¼Œè¿™äº›ä½ç½®çš„æ¦‚ç‡å°±ä¼šè¶‹è¿‘äº 0ï¼Œç›¸å½“äºæ¨¡å‹å¿½ç•¥äº†å®ƒä»¬ã€‚\n",
        "        #    mask == 0 ä¼šåˆ›å»ºä¸€ä¸ªå¸ƒå°”å¼ é‡ï¼Œpadding çš„ä½ç½®æ˜¯ Trueï¼Œå…¶ä»–ä½ç½®æ˜¯ Falseã€‚\n",
        "        #    .masked_fill_() æ˜¯ä¸€ä¸ªåŸåœ°æ“ä½œï¼Œå°† energy ä¸­å¯¹åº” True çš„ä½ç½®å¡«å……ä¸º -1e9 (ä¸€ä¸ªéå¸¸å°çš„æ•°)ã€‚\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, float(\"-1e9\"))\n",
        "\n",
        "        # 5. å¯¹å¾—åˆ†è¿›è¡Œ softmax å½’ä¸€åŒ–ï¼Œå¾—åˆ°æ³¨æ„åŠ›æƒé‡ã€‚\n",
        "        #    dim=-1 è¡¨ç¤ºåœ¨æœ€åä¸€ä¸ªç»´åº¦ä¸Šè¿›è¡Œ softmax æ“ä½œï¼Œç¡®ä¿æ¯ä¸€è¡Œçš„æƒé‡åŠ èµ·æ¥ç­‰äº 1ã€‚\n",
        "        #    `attention` çš„å½¢çŠ¶å’Œ `energy` ç›¸åŒ: (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "        # åº”ç”¨ dropoutã€‚\n",
        "        attention = self.dropout(attention)\n",
        "\n",
        "        # 6. å°†æ³¨æ„åŠ›æƒé‡ä¸ V ç›¸ä¹˜ï¼Œå¾—åˆ°åŠ æƒçš„ Valueã€‚\n",
        "        #    torch.matmul(attention, V) çš„ç»“æœ `x` çš„å½¢çŠ¶æ˜¯ (batch_size, num_heads, seq_len_q, d_k)\n",
        "        #    è¿™ä»£è¡¨äº†æ¯ä¸ªå¤´è®¡ç®—å‡ºçš„ä¸Šä¸‹æ–‡å‘é‡ã€‚\n",
        "        x = torch.matmul(attention, V)\n",
        "\n",
        "        # 7. æ‹¼æ¥å¤šå¤´çš„ç»“æœã€‚\n",
        "        #    æˆ‘ä»¬éœ€è¦æŠŠå¤šå¤´è®¡ç®—çš„ç»“æœé‡æ–°ç»„åˆæˆä¸€ä¸ª d_model ç»´åº¦çš„å‘é‡ã€‚\n",
        "        #    .transpose(1, 2) å°†å½¢çŠ¶å˜å› (batch_size, seq_len_q, num_heads, d_k)ã€‚\n",
        "        #    .contiguous() æ˜¯ä¸€ä¸ª PyTorch çš„æ“ä½œï¼Œå®ƒç¡®ä¿å¼ é‡åœ¨å†…å­˜ä¸­æ˜¯è¿ç»­å­˜å‚¨çš„ï¼Œè¿™æ˜¯ .view() æ“ä½œæ‰€å¿…éœ€çš„ã€‚\n",
        "        #    .view() å°†æœ€åä¸¤ä¸ªç»´åº¦ (num_heads, d_k) é‡æ–°åˆå¹¶ä¸º d_modelã€‚\n",
        "        #    æœ€ç»ˆå½¢çŠ¶: (batch_size, seq_len_q, d_model)\n",
        "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "\n",
        "        # 8. å°†æ‹¼æ¥åçš„ç»“æœé€šè¿‡æœ€åä¸€ä¸ªçº¿æ€§å±‚ï¼ˆå¯¹åº” Wo çŸ©é˜µï¼‰ï¼Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºã€‚\n",
        "        #    è¾“å…¥å½¢çŠ¶: (batch_size, seq_len_q, d_model)\n",
        "        #    è¾“å‡ºå½¢çŠ¶: (batch_size, seq_len_q, d_model)\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        # è¿”å›æœ€ç»ˆçš„è¾“å‡ºå¼ é‡ã€‚\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "cL1N1HN8oSC1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CzTcV5CdoSEy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å®šä¹‰ä¸€ä¸ªåä¸º PositionwiseFeedforward çš„ç±»ï¼Œå®ƒç»§æ‰¿è‡ª nn.Moduleã€‚\n",
        "# \"Positionwise\" æ„å‘³ç€è¿™ä¸ªç½‘ç»œä¼šç‹¬ç«‹åœ°ã€ç›¸åŒåœ°åº”ç”¨äºè¾“å…¥åºåˆ—ä¸­çš„æ¯ä¸€ä¸ªä½ç½®ï¼ˆæ¯ä¸€ä¸ªè¯ï¼‰ã€‚\n",
        "class PositionwiseFeedforward(nn.Module):\n",
        "    # ç±»çš„æ„é€ å‡½æ•°ã€‚\n",
        "    # d_model: è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦ã€‚\n",
        "    # d_ff: å†…éƒ¨éšè—å±‚çš„ç»´åº¦ã€‚åœ¨åŸç‰ˆ Transformer è®ºæ–‡ä¸­ï¼Œè¿™ä¸ªå€¼é€šå¸¸æ˜¯ d_model çš„ 4 å€ï¼ˆä¾‹å¦‚, d_model=512, d_ff=2048ï¼‰ã€‚\n",
        "    # dropout: Dropout çš„æ¯”ä¾‹ï¼Œé»˜è®¤ä¸º 0.1ã€‚\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        # è°ƒç”¨çˆ¶ç±» nn.Module çš„æ„é€ å‡½æ•°ã€‚\n",
        "        super().__init__()\n",
        "\n",
        "        # å®šä¹‰ç¬¬ä¸€ä¸ªçº¿æ€§å±‚ã€‚å®ƒå°†è¾“å…¥ä» d_model ç»´åº¦æ‰©å±•åˆ° d_ff ç»´åº¦ã€‚\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        # å®šä¹‰ç¬¬äºŒä¸ªçº¿æ€§å±‚ã€‚å®ƒå°†ç»´åº¦ä» d_ff å‹ç¼©å› d_modelã€‚\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        # å®šä¹‰ Dropout å±‚ã€‚\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # å®šä¹‰ ReLU æ¿€æ´»å‡½æ•°ã€‚å®ƒä¸ºæ¨¡å‹å¼•å…¥äº†éçº¿æ€§ï¼Œä½¿å¾—æ¨¡å‹èƒ½å­¦ä¹ æ›´å¤æ‚çš„å…³ç³»ã€‚\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    # forward æ–¹æ³•å®šä¹‰äº†å‰å‘ä¼ æ’­çš„é€»è¾‘ã€‚\n",
        "    # x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, seq_len, d_model)ã€‚\n",
        "    def forward(self, x):\n",
        "        # 1. å°†è¾“å…¥ x é€šè¿‡ç¬¬ä¸€ä¸ªçº¿æ€§å±‚ (fc1)ã€‚\n",
        "        #    å½¢çŠ¶å˜åŒ–: (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_ff)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        # 2. å°†ç»“æœé€šè¿‡ ReLU æ¿€æ´»å‡½æ•°ã€‚\n",
        "        #    å½¢çŠ¶ä¸å˜: (batch_size, seq_len, d_ff)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # 3. å°†ç»“æœé€šè¿‡ Dropout å±‚ã€‚\n",
        "        #    å½¢çŠ¶ä¸å˜: (batch_size, seq_len, d_ff)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # 4. å°†ç»“æœé€šè¿‡ç¬¬äºŒä¸ªçº¿æ€§å±‚ (fc2)ã€‚\n",
        "        #    å½¢çŠ¶å˜åŒ–: (batch_size, seq_len, d_ff) -> (batch_size, seq_len, d_model)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # è¿”å›æœ€ç»ˆçš„è¾“å‡ºå¼ é‡ã€‚\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "lrwssas-oSHA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "llTGrQmQoSOD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å®šä¹‰ä¸€ä¸ªåä¸º EncoderLayer çš„ç±»ï¼Œå®ƒç»§æ‰¿è‡ª nn.Moduleã€‚\n",
        "# è¿™æ˜¯æ„æˆæ•´ä¸ª Encoder çš„åŸºæœ¬å•å…ƒã€‚\n",
        "class EncoderLayer(nn.Module):\n",
        "    # ç±»çš„æ„é€ å‡½æ•°ã€‚\n",
        "    # d_model: æ¨¡å‹çš„ç»´åº¦ã€‚\n",
        "    # num_heads: å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°ã€‚\n",
        "    # d_ff: å‰é¦ˆç½‘ç»œå†…éƒ¨çš„ç»´åº¦ã€‚\n",
        "    # dropout: Dropout çš„æ¯”ä¾‹ã€‚\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°ã€‚\n",
        "        super().__init__()\n",
        "\n",
        "        # å®ä¾‹åŒ–ä¸€ä¸ªå¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—ã€‚æˆ‘ä»¬ç›´æ¥ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„ MultiHeadAttention ç±»ã€‚\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
        "\n",
        "        # å®ä¾‹åŒ–ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œæ¨¡å—ã€‚æˆ‘ä»¬ç›´æ¥ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„ PositionwiseFeedforward ç±»ã€‚\n",
        "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff, dropout)\n",
        "\n",
        "        # å®šä¹‰ä¸¤ä¸ªå±‚å½’ä¸€åŒ–ï¼ˆLayer Normalizationï¼‰æ¨¡å—ã€‚\n",
        "        # nn.LayerNorm ä¼šå¯¹è¾“å…¥çš„æœ€åä¸€ä¸ªç»´åº¦ï¼ˆè¿™é‡Œæ˜¯ d_modelï¼‰è¿›è¡Œå½’ä¸€åŒ–ã€‚\n",
        "        # è¿™æœ‰åŠ©äºç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼ŒåŠ é€Ÿæ”¶æ•›ã€‚\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # å®šä¹‰ä¸¤ä¸ª Dropout å±‚ã€‚\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    # forward æ–¹æ³•å®šä¹‰äº†å‰å‘ä¼ æ’­çš„é€»è¾‘ã€‚\n",
        "    # x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, seq_len, d_model)ã€‚\n",
        "    # mask: æ©ç ï¼Œç”¨äºåœ¨è‡ªæ³¨æ„åŠ›è®¡ç®—ä¸­å¿½ç•¥ padding çš„éƒ¨åˆ†ã€‚\n",
        "    def forward(self, x, mask):\n",
        "        # 1. --- ç¬¬ä¸€ä¸ªå­å±‚ï¼šå¤šå¤´è‡ªæ³¨æ„åŠ› ---\n",
        "\n",
        "        #    a. è®¡ç®—å¤šå¤´è‡ªæ³¨æ„åŠ›çš„è¾“å‡ºã€‚\n",
        "        #       æ³¨æ„ï¼Œå¯¹äºè‡ªæ³¨æ„åŠ›ï¼Œquery, key, value éƒ½æ˜¯ç›¸åŒçš„ï¼Œéƒ½ç­‰äºè¾“å…¥ xã€‚\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "\n",
        "        #    b. æ®‹å·®è¿æ¥ (Add) å’Œå±‚å½’ä¸€åŒ– (Norm)ã€‚\n",
        "        #       é¦–å…ˆï¼Œå°†æ³¨æ„åŠ›å±‚çš„è¾“å‡ºé€šè¿‡ä¸€ä¸ª dropout å±‚ã€‚\n",
        "        #       ç„¶åï¼Œå°† dropout åçš„ç»“æœä¸åŸå§‹è¾“å…¥ x ç›¸åŠ ï¼ˆè¿™å°±æ˜¯æ®‹å·®è¿æ¥ï¼‰ã€‚\n",
        "        #       æœ€åï¼Œå°†ç›¸åŠ çš„ç»“æœé€šè¿‡ç¬¬ä¸€ä¸ªå±‚å½’ä¸€åŒ–æ¨¡å— (norm1)ã€‚\n",
        "        #       è¿™ä¸ª `x + ...` çš„æ“ä½œå°±æ˜¯ Add & Norm ä¸­çš„ \"Add\"ã€‚\n",
        "        #       `self.norm1(...)` å°±æ˜¯ \"Norm\"ã€‚\n",
        "        x = self.norm1(x + self.dropout1(attn_output))\n",
        "\n",
        "        # 2. --- ç¬¬äºŒä¸ªå­å±‚ï¼šå‰é¦ˆç¥ç»ç½‘ç»œ ---\n",
        "\n",
        "        #    a. è®¡ç®—å‰é¦ˆç¥ç»ç½‘ç»œçš„è¾“å‡ºã€‚\n",
        "        #       è¾“å…¥æ˜¯ä¸Šä¸€ä¸ªå­å±‚å½’ä¸€åŒ–åçš„ç»“æœ xã€‚\n",
        "        forward_output = self.feed_forward(x)\n",
        "\n",
        "        #    b. å†æ¬¡è¿›è¡Œæ®‹å·®è¿æ¥ (Add) å’Œå±‚å½’ä¸€åŒ– (Norm)ã€‚\n",
        "        #       é¦–å…ˆï¼Œå°†å‰é¦ˆç½‘ç»œçš„è¾“å‡ºé€šè¿‡ç¬¬äºŒä¸ª dropout å±‚ã€‚\n",
        "        #       ç„¶åï¼Œå°† dropout åçš„ç»“æœä¸è¯¥å­å±‚çš„è¾“å…¥ x ç›¸åŠ ã€‚\n",
        "        #       æœ€åï¼Œå°†ç›¸åŠ çš„ç»“æœé€šè¿‡ç¬¬äºŒä¸ªå±‚å½’ä¸€åŒ–æ¨¡å— (norm2)ã€‚\n",
        "        x = self.norm2(x + self.dropout2(forward_output))\n",
        "\n",
        "        # è¿”å›ç¼–ç å™¨å±‚çš„æœ€ç»ˆè¾“å‡ºã€‚\n",
        "        # è¾“å‡ºçš„å½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ: (batch_size, seq_len, d_model)ã€‚\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "eb8TBHFIoSQD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BMoMKFpqoSSB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å®šä¹‰ä¸€ä¸ªåä¸º DecoderLayer çš„ç±»ï¼Œå®ƒç»§æ‰¿è‡ª nn.Moduleã€‚\n",
        "# è¿™æ˜¯æ„æˆæ•´ä¸ª Decoder çš„åŸºæœ¬å•å…ƒã€‚\n",
        "class DecoderLayer(nn.Module):\n",
        "    # ç±»çš„æ„é€ å‡½æ•°ã€‚\n",
        "    # d_model: æ¨¡å‹çš„ç»´åº¦ã€‚\n",
        "    # num_heads: å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°ã€‚\n",
        "    # d_ff: å‰é¦ˆç½‘ç»œå†…éƒ¨çš„ç»´åº¦ã€‚\n",
        "    # dropout: Dropout çš„æ¯”ä¾‹ã€‚\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°ã€‚\n",
        "        super().__init__()\n",
        "\n",
        "        # å®ä¾‹åŒ–ç¬¬ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›æ¨¡å—ï¼Œç”¨äºè§£ç å™¨è‡ªèº«çš„â€œå¸¦æ©ç è‡ªæ³¨æ„åŠ›â€ã€‚\n",
        "        # æˆ‘ä»¬ä»ç„¶ä½¿ç”¨ MultiHeadAttention ç±»ï¼Œä¹‹ååœ¨å‰å‘ä¼ æ’­æ—¶ä¼ å…¥ä¸€ä¸ªç‰¹æ®Šçš„æ©ç å³å¯ã€‚\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
        "\n",
        "        # å®ä¾‹åŒ–ç¬¬äºŒä¸ªå¤šå¤´æ³¨æ„åŠ›æ¨¡å—ï¼Œç”¨äºâ€œç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›â€ã€‚\n",
        "        # å®ƒå…³æ³¨ç¼–ç å™¨çš„è¾“å‡ºã€‚\n",
        "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
        "\n",
        "        # å®ä¾‹åŒ–ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œæ¨¡å—ã€‚\n",
        "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff, dropout)\n",
        "\n",
        "        # å®šä¹‰ä¸‰ä¸ªå±‚å½’ä¸€åŒ–æ¨¡å—ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰ä¸‰ä¸ªå­å±‚ã€‚\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # å®šä¹‰ä¸‰ä¸ª Dropout å±‚ã€‚\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "    # forward æ–¹æ³•å®šä¹‰äº†å‰å‘ä¼ æ’­çš„é€»è¾‘ã€‚\n",
        "    # x: è§£ç å™¨çš„è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, target_seq_len, d_model)ã€‚\n",
        "    # enc_output: ç¼–ç å™¨çš„è¾“å‡ºå¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, source_seq_len, d_model)ã€‚è¿™æ˜¯è§£ç å™¨éœ€è¦å…³æ³¨çš„ä¸Šä¸‹æ–‡ã€‚\n",
        "    # target_mask: ç›®æ ‡è¯­è¨€çš„æ©ç ã€‚è¿™æ—¢åŒ…å«äº†å¯¹ padding çš„æ©ç ï¼Œä¹ŸåŒ…å«äº†é˜²æ­¢çœ‹åˆ°æœªæ¥çš„â€œé¡ºåºæ©ç â€(look-ahead mask)ã€‚\n",
        "    # source_mask: æºè¯­è¨€çš„æ©ç ã€‚è¿™åªåŒ…å«äº†å¯¹ padding çš„æ©ç ã€‚\n",
        "    def forward(self, x, enc_output, source_mask, target_mask):\n",
        "        # 1. --- ç¬¬ä¸€ä¸ªå­å±‚ï¼šå¸¦æ©ç çš„å¤šå¤´è‡ªæ³¨æ„åŠ› ---\n",
        "\n",
        "        #    a. è®¡ç®—å¤šå¤´è‡ªæ³¨æ„åŠ›çš„è¾“å‡ºã€‚\n",
        "        #       è¿™é‡Œçš„ query, key, value éƒ½æ˜¯è§£ç å™¨çš„è¾“å…¥ xã€‚\n",
        "        #       æˆ‘ä»¬ä¼ å…¥ target_mask æ¥ç¡®ä¿æ¯ä¸ªä½ç½®åªèƒ½å…³æ³¨åˆ°å®ƒè‡ªå·±å’Œå®ƒå‰é¢çš„ä½ç½®ã€‚\n",
        "        self_attn_output = self.self_attn(x, x, x, target_mask)\n",
        "\n",
        "        #    b. æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ã€‚\n",
        "        x = self.norm1(x + self.dropout1(self_attn_output))\n",
        "\n",
        "        # 2. --- ç¬¬äºŒä¸ªå­å±‚ï¼šç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ› ---\n",
        "\n",
        "        #    a. è®¡ç®—ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›çš„è¾“å‡ºã€‚\n",
        "        #       è¿™é‡Œçš„å…³é”®æ˜¯ï¼š\n",
        "        #       - Query (Q) æ¥è‡ªäºä¸Šä¸€ä¸ªå­å±‚çš„è¾“å‡º x (è§£ç å™¨è‡ªèº«çš„ä¿¡æ¯)ã€‚\n",
        "        #       - Key (K) å’Œ Value (V) éƒ½æ¥è‡ªäºç¼–ç å™¨çš„è¾“å‡º enc_output (æºè¯­è¨€å¥å­çš„ä¿¡æ¯)ã€‚\n",
        "        #       - æˆ‘ä»¬ä¼ å…¥ source_maskï¼Œå› ä¸ºå®ƒä½œç”¨äº K å’Œ Vï¼Œéœ€è¦å±è”½æ‰æºè¯­è¨€å¥å­ä¸­çš„ padding éƒ¨åˆ†ã€‚\n",
        "        enc_dec_attn_output = self.enc_dec_attn(x, enc_output, enc_output, source_mask)\n",
        "\n",
        "        #    b. æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ã€‚\n",
        "        x = self.norm2(x + self.dropout2(enc_dec_attn_output))\n",
        "\n",
        "        # 3. --- ç¬¬ä¸‰ä¸ªå­å±‚ï¼šå‰é¦ˆç¥ç»ç½‘ç»œ ---\n",
        "\n",
        "        #    a. è®¡ç®—å‰é¦ˆç¥ç»ç½‘ç»œçš„è¾“å‡ºã€‚\n",
        "        forward_output = self.feed_forward(x)\n",
        "\n",
        "        #    b. æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ã€‚\n",
        "        x = self.norm3(x + self.dropout3(forward_output))\n",
        "\n",
        "        # è¿”å›è§£ç å™¨å±‚çš„æœ€ç»ˆè¾“å‡ºã€‚\n",
        "        # è¾“å‡ºçš„å½¢çŠ¶ä¸è¾“å…¥ x ç›¸åŒ: (batch_size, target_seq_len, d_model)ã€‚\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "YKRk_wA2oST0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GZ6hjXgoSVy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å®šä¹‰ä¸€ä¸ªåä¸º Encoder çš„ç±»ï¼Œå®ƒç»§æ‰¿è‡ª nn.Moduleã€‚\n",
        "# æ•´ä¸ªç¼–ç å™¨éƒ¨åˆ†ç”± N ä¸ªç›¸åŒçš„ EncoderLayer å †å è€Œæˆã€‚\n",
        "class Encoder(nn.Module):\n",
        "    # ç±»çš„æ„é€ å‡½æ•°ã€‚\n",
        "    # input_dim: è¾“å…¥è¯å…¸çš„å¤§å°ï¼ˆæ¯”å¦‚æºè¯­è¨€æœ‰ 30000 ä¸ªä¸åŒçš„è¯ï¼‰ã€‚\n",
        "    # d_model: æ¨¡å‹çš„ç»´åº¦ã€‚\n",
        "    # num_layers: ç¼–ç å™¨å±‚ (EncoderLayer) çš„æ•°é‡ (åŸè®ºæ–‡ä¸­æ˜¯ 6)ã€‚\n",
        "    # num_heads: å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°ã€‚\n",
        "    # d_ff: å‰é¦ˆç½‘ç»œå†…éƒ¨çš„ç»´åº¦ã€‚\n",
        "    # dropout: Dropout çš„æ¯”ä¾‹ã€‚\n",
        "    def __init__(self, input_dim, d_model, num_layers, num_heads, d_ff, dropout=0.1):\n",
        "        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°ã€‚\n",
        "        super().__init__()\n",
        "\n",
        "        # å®šä¹‰è¯åµŒå…¥å±‚ (Embedding Layer)ã€‚\n",
        "        # nn.Embedding ä¼šåˆ›å»ºä¸€ä¸ªæŸ¥æ‰¾è¡¨ï¼ˆlookup tableï¼‰ï¼Œå°†æ¯ä¸ªè¯çš„ç´¢å¼•ï¼ˆä¸€ä¸ªæ•´æ•°ï¼‰æ˜ å°„åˆ°ä¸€ä¸ª d_model ç»´çš„å‘é‡ã€‚\n",
        "        self.embedding = nn.Embedding(input_dim, d_model)\n",
        "\n",
        "        # å®ä¾‹åŒ–æˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„ä½ç½®ç¼–ç æ¨¡å—ã€‚\n",
        "        self.pos_encoding = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        # åˆ›å»ºä¸€ä¸ªæ¨¡å—åˆ—è¡¨ (ModuleList) æ¥å­˜æ”¾æ‰€æœ‰çš„ç¼–ç å™¨å±‚ã€‚\n",
        "        # nn.ModuleList æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„åˆ—è¡¨ï¼Œå®ƒå¯ä»¥æ­£ç¡®åœ°æ³¨å†Œå®ƒåŒ…å«çš„æ‰€æœ‰æ¨¡å—ï¼Œè®© PyTorch çŸ¥é“å®ƒä»¬æ˜¯æ¨¡å‹çš„ä¸€éƒ¨åˆ†ã€‚\n",
        "        # æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª for å¾ªç¯æ¥åˆ›å»º num_layers ä¸ª EncoderLayer å®ä¾‹ã€‚\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        # å®šä¹‰ä¸€ä¸ª Dropout å±‚ã€‚\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # forward æ–¹æ³•å®šä¹‰äº†å‰å‘ä¼ æ’­çš„é€»è¾‘ã€‚\n",
        "    # src: æºè¯­è¨€å¥å­çš„è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, src_len)ï¼Œå†…å®¹æ˜¯è¯çš„ç´¢å¼•ã€‚\n",
        "    # mask: æºè¯­è¨€çš„æ©ç ã€‚\n",
        "    def forward(self, src, mask):\n",
        "        # 1. å°†è¾“å…¥çš„è¯ç´¢å¼•é€šè¿‡åµŒå…¥å±‚ï¼Œè½¬æ¢ä¸ºè¯å‘é‡ã€‚\n",
        "        #    å½¢çŠ¶å˜åŒ–: (batch_size, src_len) -> (batch_size, src_len, d_model)\n",
        "        src = self.embedding(src)\n",
        "\n",
        "        # 2. å°†ä½ç½®ç¼–ç æ·»åŠ åˆ°è¯å‘é‡ä¸Šã€‚\n",
        "        #    å½¢çŠ¶ä¸å˜: (batch_size, src_len, d_model)\n",
        "        src = self.pos_encoding(src)\n",
        "\n",
        "        # 3. è®©æ•°æ®ä¾æ¬¡é€šè¿‡ ModuleList ä¸­çš„æ¯ä¸€ä¸ªç¼–ç å™¨å±‚ã€‚\n",
        "        #    æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª for å¾ªç¯æ¥éå† self.layersã€‚\n",
        "        #    åœ¨æ¯ä¸€å±‚ï¼Œè¾“å…¥æ˜¯ä¸Šä¸€å±‚çš„è¾“å‡ºã€‚\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, mask)\n",
        "\n",
        "        # è¿”å›ç¼–ç å™¨æœ€ç»ˆçš„è¾“å‡ºã€‚\n",
        "        # å½¢çŠ¶: (batch_size, src_len, d_model)\n",
        "        return src\n"
      ],
      "metadata": {
        "id": "T99yTFkUoSYB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kl8WsBxKoSaI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å®šä¹‰ä¸€ä¸ªåä¸º Decoder çš„ç±»ï¼Œå®ƒç»§æ‰¿è‡ª nn.Moduleã€‚\n",
        "# æ•´ä¸ªè§£ç å™¨éƒ¨åˆ†ç”± N ä¸ªç›¸åŒçš„ DecoderLayer å †å è€Œæˆã€‚\n",
        "class Decoder(nn.Module):\n",
        "    # ç±»çš„æ„é€ å‡½æ•°ã€‚\n",
        "    # output_dim: è¾“å‡ºè¯å…¸çš„å¤§å°ï¼ˆæ¯”å¦‚ç›®æ ‡è¯­è¨€æœ‰ 32000 ä¸ªä¸åŒçš„è¯ï¼‰ã€‚\n",
        "    # d_model, num_layers, num_heads, d_ff, dropout: å‚æ•°å«ä¹‰ä¸ Encoder ç›¸åŒã€‚\n",
        "    def __init__(self, output_dim, d_model, num_layers, num_heads, d_ff, dropout=0.1):\n",
        "        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°ã€‚\n",
        "        super().__init__()\n",
        "\n",
        "        # å®šä¹‰ç›®æ ‡è¯­è¨€çš„è¯åµŒå…¥å±‚ã€‚\n",
        "        self.embedding = nn.Embedding(output_dim, d_model)\n",
        "\n",
        "        # å®ä¾‹åŒ–ä½ç½®ç¼–ç æ¨¡å—ã€‚\n",
        "        self.pos_encoding = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        # åˆ›å»ºä¸€ä¸ª ModuleList æ¥å­˜æ”¾æ‰€æœ‰çš„è§£ç å™¨å±‚ã€‚\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        # å®šä¹‰ä¸€ä¸ªæœ€ç»ˆçš„çº¿æ€§å±‚ã€‚\n",
        "        # è¿™ä¸ªå±‚çš„ä½œç”¨æ˜¯å°†è§£ç å™¨æœ€åä¸€å±‚çš„è¾“å‡ºï¼ˆd_model ç»´åº¦ï¼‰æ˜ å°„åˆ°æ•´ä¸ªç›®æ ‡è¯å…¸çš„å¤§å°ï¼ˆoutput_dim ç»´åº¦ï¼‰ã€‚\n",
        "        # è¿™æ ·ï¼Œå¯¹äºæ¯ä¸ªä½ç½®ï¼Œæˆ‘ä»¬éƒ½èƒ½å¾—åˆ°ä¸€ä¸ªä»£è¡¨æ¯ä¸ªè¯å¾—åˆ†çš„å‘é‡ã€‚\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "\n",
        "        # å®šä¹‰ Dropout å±‚ã€‚\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # forward æ–¹æ³•å®šä¹‰äº†å‰å‘ä¼ æ’­çš„é€»è¾‘ã€‚\n",
        "    # trg: ç›®æ ‡è¯­è¨€å¥å­çš„è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, trg_len)ã€‚\n",
        "    # enc_src: ç¼–ç å™¨çš„è¾“å‡ºï¼Œå½¢çŠ¶ä¸º (batch_size, src_len, d_model)ã€‚\n",
        "    # trg_mask: ç›®æ ‡è¯­è¨€çš„æ©ç ã€‚\n",
        "    # src_mask: æºè¯­è¨€çš„æ©ç ã€‚\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        # 1. å°†ç›®æ ‡è¯­è¨€çš„è¯ç´¢å¼•é€šè¿‡åµŒå…¥å±‚ï¼Œè½¬æ¢ä¸ºè¯å‘é‡ã€‚\n",
        "        #    å½¢çŠ¶å˜åŒ–: (batch_size, trg_len) -> (batch_size, trg_len, d_model)\n",
        "        trg = self.embedding(trg)\n",
        "\n",
        "        # 2. å°†ä½ç½®ç¼–ç æ·»åŠ åˆ°è¯å‘é‡ä¸Šã€‚\n",
        "        #    å½¢çŠ¶ä¸å˜: (batch_size, trg_len, d_model)\n",
        "        trg = self.pos_encoding(trg)\n",
        "\n",
        "        # 3. è®©æ•°æ®ä¾æ¬¡é€šè¿‡ ModuleList ä¸­çš„æ¯ä¸€ä¸ªè§£ç å™¨å±‚ã€‚\n",
        "        #    æ¯ä¸€å±‚éƒ½éœ€è¦æ¥æ”¶ä¸Šä¸€æ­¥çš„è¾“å‡º trg, ç¼–ç å™¨çš„è¾“å‡º enc_src, ä»¥åŠä¸¤ç§æ©ç ã€‚\n",
        "        for layer in self.layers:\n",
        "            trg = layer(trg, enc_src, src_mask, trg_mask)\n",
        "\n",
        "        # 4. å°†è§£ç å™¨æœ€åä¸€å±‚çš„è¾“å‡ºé€šè¿‡æœ€ç»ˆçš„çº¿æ€§å±‚ fc_outã€‚\n",
        "        #    å½¢çŠ¶å˜åŒ–: (batch_size, trg_len, d_model) -> (batch_size, trg_len, output_dim)\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        # è¿”å›æœ€ç»ˆçš„è¾“å‡ºï¼ˆä¹Ÿç§°ä¸º logitsï¼‰ã€‚\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "0ygJj1_YoScY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x40Jlr8GoSec"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å®šä¹‰æœ€ç»ˆçš„ Transformer æ¨¡å‹ç±»ã€‚\n",
        "class Transformer(nn.Module):\n",
        "    # ç±»çš„æ„é€ å‡½æ•°ã€‚\n",
        "    # encoder: ä¸€ä¸ª Encoder ç±»çš„å®ä¾‹ã€‚\n",
        "    # decoder: ä¸€ä¸ª Decoder ç±»çš„å®ä¾‹ã€‚\n",
        "    # src_pad_idx: æºè¯­è¨€ä¸­å¡«å……ç¬¦å· <pad> çš„ç´¢å¼•ã€‚\n",
        "    # trg_pad_idx: ç›®æ ‡è¯­è¨€ä¸­å¡«å……ç¬¦å· <pad> çš„ç´¢å¼•ã€‚\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx):\n",
        "        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°ã€‚\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "\n",
        "    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•æ¥åˆ›å»ºæºè¯­è¨€çš„æ©ç ã€‚\n",
        "    # src: æºè¯­è¨€è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, src_len)ã€‚\n",
        "    def make_src_mask(self, src):\n",
        "        # 1. æ£€æŸ¥ src å¼ é‡ä¸­å“ªäº›å…ƒç´ ç­‰äºå¡«å……ç´¢å¼•ã€‚\n",
        "        #    (src != self.src_pad_idx) ä¼šç”Ÿæˆä¸€ä¸ªå¸ƒå°”å¼ é‡ï¼Œpadding çš„ä½ç½®æ˜¯ Falseï¼Œé padding æ˜¯ Trueã€‚\n",
        "        #    å½¢çŠ¶: (batch_size, src_len)\n",
        "        # 2. åœ¨æœ€åä¸¤ä¸ªç»´åº¦ä¸Šå¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œä»¥åŒ¹é…å¤šå¤´æ³¨æ„åŠ›çš„æœŸæœ›å½¢çŠ¶ã€‚\n",
        "        #    .unsqueeze(1).unsqueeze(2) ä¼šå°†å½¢çŠ¶å˜ä¸º (batch_size, 1, 1, src_len)ã€‚\n",
        "        #    è¿™ä¸ªå½¢çŠ¶å¯ä»¥å’Œæ³¨æ„åŠ›å¾—åˆ†çŸ©é˜µ (batch_size, num_heads, seq_len, seq_len) è¿›è¡Œå¹¿æ’­ã€‚\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        return src_mask\n",
        "\n",
        "    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•æ¥åˆ›å»ºç›®æ ‡è¯­è¨€çš„æ©ç ã€‚\n",
        "    # trg: ç›®æ ‡è¯­è¨€è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, trg_len)ã€‚\n",
        "    def make_trg_mask(self, trg):\n",
        "        # 1. åˆ›å»º padding æ©ç ï¼Œé€»è¾‘ä¸ src_mask ç›¸åŒã€‚\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        # å½¢çŠ¶: (batch_size, 1, 1, trg_len)\n",
        "\n",
        "        # 2. åˆ›å»ºâ€œé¡ºåºâ€æ©ç  (look-ahead mask)ï¼Œé˜²æ­¢çœ‹åˆ°æœªæ¥çš„è¯ã€‚\n",
        "        trg_len = trg.shape[1]\n",
        "        #    torch.tril() ä¼šåˆ›å»ºä¸€ä¸ªä¸‹ä¸‰è§’çŸ©é˜µã€‚\n",
        "        #    torch.ones((trg_len, trg_len)) åˆ›å»ºä¸€ä¸ªå…¨ 1 çš„æ–¹é˜µã€‚\n",
        "        #    torch.tril(...) ä¼šå°†è¿™ä¸ªæ–¹é˜µçš„å³ä¸Šéƒ¨åˆ†å˜ä¸º 0ã€‚\n",
        "        #    ä¾‹å¦‚ trg_len=3, ç»“æœæ˜¯:\n",
        "        #    [[1, 0, 0],\n",
        "        #     [1, 1, 0],\n",
        "        #     [1, 1, 1]]\n",
        "        #    .to(device) ç¡®ä¿æ©ç å’Œæ•°æ®åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Šï¼ˆCPU æˆ– GPUï¼‰ã€‚\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=device)).bool()\n",
        "        # å½¢çŠ¶: (trg_len, trg_len)\n",
        "\n",
        "        # 3. å°† padding æ©ç å’Œé¡ºåºæ©ç ç»“åˆèµ·æ¥ã€‚\n",
        "        #    ä½¿ç”¨é€»è¾‘ä¸ (&) æ“ä½œã€‚åªæœ‰å½“ä¸¤ä¸ªæ©ç åœ¨æŸä¸ªä½ç½®éƒ½ä¸º True æ—¶ï¼Œæœ€ç»ˆç»“æœæ‰ä¸º Trueã€‚\n",
        "        #    trg_pad_mask çš„å½¢çŠ¶æ˜¯ (batch_size, 1, 1, trg_len)\n",
        "        #    trg_sub_mask çš„å½¢çŠ¶æ˜¯ (trg_len, trg_len)\n",
        "        #    PyTorch çš„å¹¿æ’­æœºåˆ¶ä¼šè‡ªåŠ¨å¤„ç†è¿™ä¸¤ä¸ªä¸åŒå½¢çŠ¶çš„å¼ é‡ã€‚\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    # forward æ–¹æ³•å®šä¹‰äº†æ•´ä¸ªæ¨¡å‹çš„å‰å‘ä¼ æ’­ã€‚\n",
        "    # src: æºè¯­è¨€è¾“å…¥ã€‚\n",
        "    # trg: ç›®æ ‡è¯­è¨€è¾“å…¥ã€‚\n",
        "    def forward(self, src, trg):\n",
        "        # 1. åˆ›å»ºæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€çš„æ©ç ã€‚\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        # 2. å°†æºè¯­è¨€å’Œæ©ç è¾“å…¥ç¼–ç å™¨ï¼Œå¾—åˆ°ç¼–ç å™¨çš„è¾“å‡ºã€‚\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "        # 3. å°†ç›®æ ‡è¯­è¨€ã€ç¼–ç å™¨è¾“å‡ºä»¥åŠä¸¤ç§æ©ç è¾“å…¥è§£ç å™¨ï¼Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºã€‚\n",
        "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # è¿”å›è¾“å‡ºã€‚\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "3M915Tt7oShA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7wHuMyV2oSjM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9XpZ1qXFoSlK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- æ¨¡å‹è¶…å‚æ•°å®šä¹‰ ---\n",
        "\n",
        "# INPUT_DIM: è¾“å…¥è¯å…¸çš„å¤§å°ã€‚\n",
        "# å‡è®¾æˆ‘ä»¬çš„æºè¯­è¨€ï¼ˆä¾‹å¦‚ä¸­æ–‡ï¼‰è¯å…¸ä¸­æœ‰ 5000 ä¸ªç‹¬ç‰¹çš„è¯ã€‚\n",
        "INPUT_DIM = 5000\n",
        "\n",
        "# OUTPUT_DIM: è¾“å‡ºè¯å…¸çš„å¤§å°ã€‚\n",
        "# å‡è®¾æˆ‘ä»¬çš„ç›®æ ‡è¯­è¨€ï¼ˆä¾‹å¦‚è‹±æ–‡ï¼‰è¯å…¸ä¸­æœ‰ 5000 ä¸ªç‹¬ç‰¹çš„è¯ã€‚\n",
        "OUTPUT_DIM = 5000\n",
        "\n",
        "# D_MODEL: æ¨¡å‹çš„ç»´åº¦ï¼Œä¹Ÿå°±æ˜¯è¯åµŒå…¥å‘é‡çš„ç»´åº¦ã€‚\n",
        "# è¿™æ˜¯ Transformer æ¨¡å‹ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒç»´åº¦ï¼Œå®ƒè´¯ç©¿æ•´ä¸ªæ¨¡å‹ã€‚\n",
        "# è®ºæ–‡ä¸­è®¾ç½®ä¸º 512ã€‚\n",
        "D_MODEL = 512\n",
        "\n",
        "# NUM_LAYERS: ç¼–ç å™¨å’Œè§£ç å™¨ä¸­å †å çš„å±‚æ•°ã€‚\n",
        "# è®ºæ–‡ä¸­è®¾ç½®ä¸º 6ã€‚\n",
        "NUM_LAYERS = 6\n",
        "\n",
        "# NUM_HEADS: å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„â€œå¤´â€æ•°ã€‚\n",
        "# æ³¨æ„ï¼šD_MODEL å¿…é¡»èƒ½å¤Ÿè¢« NUM_HEADS æ•´é™¤ (512 % 8 == 0)ã€‚\n",
        "# è®ºæ–‡ä¸­è®¾ç½®ä¸º 8ã€‚\n",
        "NUM_HEADS = 8\n",
        "\n",
        "# D_FF: å‰é¦ˆç¥ç»ç½‘ç»œå†…éƒ¨çš„éšè—å±‚ç»´åº¦ã€‚\n",
        "# è®ºæ–‡ä¸­å»ºè®®è®¾ç½®ä¸º D_MODEL çš„ 4 å€ã€‚\n",
        "D_FF = 2048\n",
        "\n",
        "# DROPOUT: Dropout çš„æ¯”ä¾‹ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚\n",
        "# è®ºæ–‡ä¸­è®¾ç½®ä¸º 0.1ã€‚\n",
        "DROPOUT = 0.1\n",
        "\n",
        "# SRC_PAD_IDX: æºè¯­è¨€ä¸­ï¼Œç”¨äºå¡«å……ï¼ˆpaddingï¼‰çš„ç‰¹æ®Šç¬¦å· <pad> åœ¨è¯å…¸ä¸­çš„ç´¢å¼•ã€‚\n",
        "# æˆ‘ä»¬å‡è®¾å®ƒçš„ç´¢å¼•æ˜¯ 0ã€‚è¿™ä¸ªå€¼åœ¨åˆ›å»ºæ©ç æ—¶è‡³å…³é‡è¦ã€‚\n",
        "SRC_PAD_IDX = 0\n",
        "\n",
        "# TRG_PAD_IDX: ç›®æ ‡è¯­è¨€ä¸­ï¼Œç”¨äºå¡«å……çš„ç‰¹æ®Šç¬¦å· <pad> åœ¨è¯å…¸ä¸­çš„ç´¢å¼•ã€‚\n",
        "# æˆ‘ä»¬ä¹Ÿå‡è®¾å®ƒçš„ç´¢å¼•æ˜¯ 0ã€‚\n",
        "TRG_PAD_IDX = 0\n"
      ],
      "metadata": {
        "id": "5TsAS1vfoSnW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8mzHTjlAoSpY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- æ¨¡å‹å®ä¾‹åŒ– ---\n",
        "\n",
        "# 1. å®ä¾‹åŒ–ç¼–ç å™¨ (Encoder)ã€‚\n",
        "#    æˆ‘ä»¬å°†ä¸Šé¢å®šä¹‰çš„æ‰€æœ‰ç›¸å…³è¶…å‚æ•°ä½œä¸ºå‚æ•°ä¼ å…¥ã€‚\n",
        "enc = Encoder(INPUT_DIM,\n",
        "              D_MODEL,\n",
        "              NUM_LAYERS,\n",
        "              NUM_HEADS,\n",
        "              D_FF,\n",
        "              DROPOUT)\n",
        "\n",
        "# 2. å®ä¾‹åŒ–è§£ç å™¨ (Decoder)ã€‚\n",
        "dec = Decoder(OUTPUT_DIM,\n",
        "              D_MODEL,\n",
        "              NUM_LAYERS,\n",
        "              NUM_HEADS,\n",
        "              D_FF,\n",
        "              DROPOUT)\n",
        "\n",
        "# 3. å®ä¾‹åŒ–æœ€ç»ˆçš„ Transformer æ¨¡å‹ã€‚\n",
        "#    å®ƒæ¥æ”¶æˆ‘ä»¬åˆšåˆšåˆ›å»ºçš„ç¼–ç å™¨å’Œè§£ç å™¨å®ä¾‹ï¼Œä»¥åŠå¡«å……ç´¢å¼•ã€‚\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX)\n",
        "\n",
        "# 4. å°†æ¨¡å‹ç§»åŠ¨åˆ°æˆ‘ä»¬ä¹‹å‰è®¾ç½®å¥½çš„è®¾å¤‡ä¸Šï¼ˆGPU æˆ– CPUï¼‰ã€‚\n",
        "#    .to(device) æ˜¯ä¸€ä¸ª PyTorch æ–¹æ³•ï¼Œç”¨äºå°†æ¨¡å‹çš„æ‰€æœ‰å‚æ•°å’Œç¼“å†²åŒºç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ã€‚\n",
        "#    è¿™æ˜¯ä½¿ç”¨ GPU åŠ é€Ÿæ‰€å¿…éœ€çš„æ­¥éª¤ã€‚\n",
        "model.to(device)\n",
        "\n",
        "# (å¯é€‰) æ‰“å°ä¸€ä¸‹æ¨¡å‹çš„æ€»å‚æ•°æ•°é‡ï¼Œæ„Ÿå—ä¸€ä¸‹å®ƒçš„è§„æ¨¡ã€‚\n",
        "def count_parameters(model):\n",
        "    # sum(p.numel() for p in model.parameters() if p.requires_grad) æ˜¯ä¸€ä¸ª Python çš„ç”Ÿæˆå™¨è¡¨è¾¾å¼ã€‚\n",
        "    # model.parameters() ä¼šè¿”å›æ¨¡å‹æ‰€æœ‰å¯å­¦ä¹ çš„å‚æ•°ï¼ˆæƒé‡å’Œåç½®ï¼‰ã€‚\n",
        "    # p.requires_grad æ£€æŸ¥è¿™ä¸ªå‚æ•°æ˜¯å¦éœ€è¦è®¡ç®—æ¢¯åº¦ï¼ˆå³æ˜¯å¦åœ¨è®­ç»ƒä¸­è¢«æ›´æ–°ï¼‰ã€‚\n",
        "    # p.numel() è¿”å›å‚æ•° p ä¸­å…ƒç´ çš„æ€»æ•°ã€‚\n",
        "    # sum(...) å°†æ‰€æœ‰å‚æ•°çš„å…ƒç´ æ•°é‡åŠ èµ·æ¥ï¼Œå¾—åˆ°æ¨¡å‹çš„æ€»å‚æ•°é‡ã€‚\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# æ‰“å°æ€»å‚æ•°é‡ï¼Œå¹¶ç”¨é€—å·è¿›è¡Œæ ¼å¼åŒ–ï¼Œä½¿å…¶æ›´æ˜“è¯»ã€‚\n",
        "print(f'è¿™ä¸ªæ¨¡å‹å…±æœ‰ {count_parameters(model):,} ä¸ªå¯è®­ç»ƒçš„å‚æ•°')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8435SgoSrr",
        "outputId": "b180d11c-6f9e-4fca-b1ad-07a3ed103d2d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è¿™ä¸ªæ¨¡å‹å…±æœ‰ 51,823,496 ä¸ªå¯è®­ç»ƒçš„å‚æ•°\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b09SFFoooStc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- å¥å…¨æ€§æ£€æŸ¥ ---\n",
        "\n",
        "# è®¾ç½®ä¸€äº›ç”¨äºæµ‹è¯•çš„ç»´åº¦\n",
        "BATCH_SIZE = 128  # æ‰¹æ¬¡å¤§å°ï¼Œå³ä¸€æ¬¡å¤„ç† 128 ä¸ªå¥å­ã€‚\n",
        "SRC_LEN = 30      # æºè¯­è¨€å¥å­çš„é•¿åº¦ï¼Œå‡è®¾ä¸º 30 ä¸ªè¯ã€‚\n",
        "TRG_LEN = 35      # ç›®æ ‡è¯­è¨€å¥å­çš„é•¿åº¦ï¼Œå‡è®¾ä¸º 35 ä¸ªè¯ã€‚\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªå‡çš„æºè¯­è¨€è¾“å…¥å¼ é‡ã€‚\n",
        "# torch.randint(low, high, size) ä¼šç”Ÿæˆä¸€ä¸ªåœ¨ [low, high) åŒºé—´å†…çš„éšæœºæ•´æ•°å¼ é‡ã€‚\n",
        "# æˆ‘ä»¬ç”Ÿæˆçš„å€¼åœ¨ [0, INPUT_DIM) ä¹‹é—´ï¼Œæ¨¡æ‹Ÿè¯å…¸ä¸­çš„è¯ç´¢å¼•ã€‚\n",
        "# size=(BATCH_SIZE, SRC_LEN) æŒ‡å®šäº†å¼ é‡çš„å½¢çŠ¶ã€‚\n",
        "# .to(device) ç¡®ä¿è¿™ä¸ªæ•°æ®å¼ é‡ä¹Ÿåœ¨ GPU ä¸Šï¼Œä¸æ¨¡å‹åœ¨åŒä¸€ä¸ªè®¾å¤‡ã€‚\n",
        "src = torch.randint(0, INPUT_DIM, (BATCH_SIZE, SRC_LEN)).to(device)\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªå‡çš„ç›®æ ‡è¯­è¨€è¾“å…¥å¼ é‡ã€‚\n",
        "trg = torch.randint(0, OUTPUT_DIM, (BATCH_SIZE, TRG_LEN)).to(device)\n",
        "\n",
        "# æ‰“å°ä¸€ä¸‹è¾“å…¥æ•°æ®çš„å½¢çŠ¶ï¼Œä»¥ä¾¿å¯¹æ¯”ã€‚\n",
        "print(\"è¾“å…¥ src çš„å½¢çŠ¶:\", src.shape)\n",
        "print(\"è¾“å…¥ trg çš„å½¢çŠ¶:\", trg.shape)\n",
        "print(\"-\" * 30) # æ‰“å°ä¸€æ¡åˆ†å‰²çº¿\n",
        "\n",
        "# æ ¸å¿ƒæ­¥éª¤ï¼šå°†å‡æ•°æ®å–‚ç»™æ¨¡å‹ï¼Œè¿›è¡Œä¸€æ¬¡å®Œæ•´çš„å‰å‘ä¼ æ’­ã€‚\n",
        "# model(src, trg) ä¼šè‡ªåŠ¨è°ƒç”¨æˆ‘ä»¬ Transformer ç±»ä¸­å®šä¹‰çš„ forward æ–¹æ³•ã€‚\n",
        "output = model(src, trg)\n",
        "\n",
        "# æ‰“å°è¾“å‡ºæ•°æ®çš„å½¢çŠ¶ã€‚\n",
        "print(\"æ¨¡å‹è¾“å‡º output çš„å½¢çŠ¶:\", output.shape)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- éªŒè¯è¾“å‡ºå½¢çŠ¶ ---\n",
        "# æˆ‘ä»¬æœŸæœ›çš„è¾“å‡ºå½¢çŠ¶åº”è¯¥æ˜¯ (BATCH_SIZE, TRG_LEN, OUTPUT_DIM)\n",
        "# å› ä¸ºå¯¹äºç›®æ ‡åºåˆ—ä¸­çš„æ¯ä¸€ä¸ªè¯ï¼Œæ¨¡å‹éƒ½åº”è¯¥é¢„æµ‹ä¸€ä¸ªåœ¨æ•´ä¸ªç›®æ ‡è¯å…¸ä¸Šçš„å¾—åˆ†åˆ†å¸ƒã€‚\n",
        "expected_shape = (BATCH_SIZE, TRG_LEN, OUTPUT_DIM)\n",
        "if output.shape == expected_shape:\n",
        "    print(\"ğŸ‰ æ­å–œï¼æ¨¡å‹ç»“æ„æ­£ç¡®ï¼Œå¥å…¨æ€§æ£€æŸ¥é€šè¿‡ï¼\")\n",
        "    print(f\"è¾“å‡ºå½¢çŠ¶ ({output.shape}) ä¸æœŸæœ›å½¢çŠ¶ ({expected_shape}) å®Œå…¨ä¸€è‡´ã€‚\")\n",
        "else:\n",
        "    print(\"ğŸ˜¥ æ¨¡å‹ç»“æ„ä¼¼ä¹æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚\")\n",
        "    print(f\"è¾“å‡ºå½¢çŠ¶æ˜¯ {output.shape}, ä½†æˆ‘ä»¬æœŸæœ›çš„æ˜¯ {expected_shape}ã€‚\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU8hWbyyoSvs",
        "outputId": "92f644b3-b888-4e4c-a9fc-26e7723fc346"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è¾“å…¥ src çš„å½¢çŠ¶: torch.Size([128, 30])\n",
            "è¾“å…¥ trg çš„å½¢çŠ¶: torch.Size([128, 35])\n",
            "------------------------------\n",
            "æ¨¡å‹è¾“å‡º output çš„å½¢çŠ¶: torch.Size([128, 35, 5000])\n",
            "------------------------------\n",
            "ğŸ‰ æ­å–œï¼æ¨¡å‹ç»“æ„æ­£ç¡®ï¼Œå¥å…¨æ€§æ£€æŸ¥é€šè¿‡ï¼\n",
            "è¾“å‡ºå½¢çŠ¶ (torch.Size([128, 35, 5000])) ä¸æœŸæœ›å½¢çŠ¶ ((128, 35, 5000)) å®Œå…¨ä¸€è‡´ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u03PhZaToSxu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6HkZ7svoSz0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NVqnP1qboS2C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_A4U3-MRoS4I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xGJa4VxVoS6L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "__sE93H2oS8I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nih7gS_goS-W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pPkfP4-roTAf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YT0utu8oTCd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g0N_s8z6oTEb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3c9QGaLcoTGw"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}