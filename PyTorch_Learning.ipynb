{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E5DNHaZEyOC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a_verify_install.py\n",
        "\n",
        "import torch\n",
        "\n",
        "# 打印PyTorch版本\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "\n",
        "# 检查GPU是否可用\n",
        "is_cuda_available = torch.cuda.is_available()\n",
        "print(f\"CUDA (GPU) Available: {is_cuda_available}\")\n",
        "\n",
        "if is_cuda_available:\n",
        "    # 打印GPU数量\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    # 打印当前GPU设备名称\n",
        "    print(f\"Current GPU Name: {torch.cuda.get_device_name(0)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwLbq2kBE7ZR",
        "outputId": "2b444aa0-dc68-424b-94a3-631696e6dda1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.8.0+cu126\n",
            "CUDA (GPU) Available: True\n",
            "Number of GPUs: 1\n",
            "Current GPU Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b_tensors_demo.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 1. 创建Tensor\n",
        "# 从列表创建\n",
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "print(f\"Tensor from list:\\n {x_data}\\n\")\n",
        "\n",
        "# 从NumPy数组创建 (共享内存)\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "print(f\"Tensor from NumPy:\\n {x_np}\\n\")\n",
        "\n",
        "# 创建指定形状的全1或随机Tensor\n",
        "shape = (2, 3,)\n",
        "ones_tensor = torch.ones(shape)\n",
        "rand_tensor = torch.rand(shape)\n",
        "print(f\"Ones Tensor:\\n {ones_tensor}\\n\")\n",
        "print(f\"Random Tensor:\\n {rand_tensor}\\n\")\n",
        "\n",
        "# 2. Tensor的属性\n",
        "tensor = torch.rand(3, 4)\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\\n\")\n",
        "\n",
        "# 3. Tensor操作 (类似NumPy)\n",
        "# 索引和切片\n",
        "tensor = torch.ones(4, 4)\n",
        "tensor[:, 1] = 0 # 将第二列全部置为0\n",
        "print(f\"Sliced Tensor:\\n {tensor}\\n\")\n",
        "\n",
        "# 矩阵乘法\n",
        "mat_mul = tensor.matmul(tensor.T) # .T 是转置\n",
        "print(f\"Matrix Multiplication:\\n {mat_mul}\\n\")\n",
        "\n",
        "# 元素级乘法\n",
        "elem_mul = tensor.mul(tensor)\n",
        "# 或者 torch.mul(tensor, tensor)\n",
        "print(f\"Element-wise Multiplication:\\n {elem_mul}\\n\")\n",
        "\n",
        "# Tensor与标量的运算\n",
        "added_tensor = tensor.add(5)\n",
        "print(f\"Tensor after adding 5:\\n {added_tensor}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9WxFF6tE7m3",
        "outputId": "a3cf9b63-d9d6-41c5-dc24-92a6c249e16c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor from list:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "\n",
            "Tensor from NumPy:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "\n",
            "Ones Tensor:\n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "Random Tensor:\n",
            " tensor([[0.1106, 0.5699, 0.5976],\n",
            "        [0.3549, 0.4626, 0.0076]])\n",
            "\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n",
            "\n",
            "Sliced Tensor:\n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "\n",
            "Matrix Multiplication:\n",
            " tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n",
            "\n",
            "Element-wise Multiplication:\n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "\n",
            "Tensor after adding 5:\n",
            " tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c_autograd_demo.py\n",
        "\n",
        "import torch\n",
        "\n",
        "# 创建一个需要梯度的Tensor，这是模型参数的模拟\n",
        "# requires_grad=True 告诉PyTorch需要追踪对该Tensor的所有操作\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# 定义一个简单的线性模型\n",
        "x = torch.tensor(3.0)\n",
        "y = w * x + b  # y = 2*3 + 1 = 7\n",
        "\n",
        "# 假设我们有一个目标值\n",
        "target = torch.tensor(10.0)\n",
        "\n",
        "# 计算损失 (这里用简单的平方差)\n",
        "loss = (target - y)**2 # loss = (10 - 7)^2 = 9\n",
        "\n",
        "# 执行反向传播，计算梯度\n",
        "# loss是一个标量，所以可以直接调用.backward()\n",
        "loss.backward()\n",
        "\n",
        "# 打印梯度\n",
        "# d(loss)/dw = d((10 - (w*x+b))^2)/dw = 2 * (10 - (w*x+b)) * (-x) = 2 * 3 * (-3) = -18\n",
        "print(f\"Gradient of w (dw): {w.grad}\")\n",
        "\n",
        "# d(loss)/db = d((10 - (w*x+b))^2)/db = 2 * (10 - (w*x+b)) * (-1) = 2 * 3 * (-1) = -6\n",
        "print(f\"Gradient of b (db): {b.grad}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP4anmEfE7st",
        "outputId": "bf6e74f6-a1e0-4389-f8c2-4e53ba8768ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of w (dw): -18.0\n",
            "Gradient of b (db): -6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# d_nn_module_demo.py\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# 定义一个简单的全连接神经网络\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # 必须先调用父类的__init__方法\n",
        "        super().__init__()\n",
        "\n",
        "        # 定义网络的层次结构\n",
        "        # nn.Linear(input_features, output_features) 定义一个全连接层\n",
        "        self.layer1 = nn.Linear(10, 32) # 输入10个特征，输出32个特征\n",
        "        self.activation1 = nn.ReLU()   # ReLU激活函数\n",
        "        self.layer2 = nn.Linear(32, 1) # 输入32个特征，输出1个特征 (例如，回归任务)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 定义数据的前向传播路径\n",
        "        x = self.layer1(x)\n",
        "        x = self.activation1(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "# 实例化模型\n",
        "model = SimpleNet()\n",
        "print(model)\n",
        "\n",
        "# 创建一个假的输入数据 (batch_size=5, features=10)\n",
        "dummy_input = torch.randn(5, 10)\n",
        "\n",
        "# 将数据传入模型，得到输出\n",
        "output = model(dummy_input)\n",
        "\n",
        "print(f\"\\nInput shape: {dummy_input.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFf_ClSsE7xL",
        "outputId": "32d95d2e-792b-452b-cea2-27e5a48bf066"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNet(\n",
            "  (layer1): Linear(in_features=10, out_features=32, bias=True)\n",
            "  (activation1): ReLU()\n",
            "  (layer2): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Input shape: torch.Size([5, 10])\n",
            "Output shape: torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Og4m-NDWFpdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TRBdsKPaFppm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KcYyD_3fFpvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Colab单元格中运行\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# 定义一个更结构化的神经网络\n",
        "class RegressionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # 定义网络的输入、隐藏和输出层的维度\n",
        "        input_features = 10  # 假设我们的数据有10个特征\n",
        "        hidden_units_1 = 64\n",
        "        hidden_units_2 = 32\n",
        "        output_features = 1   # 回归任务，输出1个值\n",
        "\n",
        "        # 使用 nn.Sequential 将网络层串联起来\n",
        "        # 这是一个清晰、模块化的方式来定义模型\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_features, hidden_units_1),\n",
        "            nn.ReLU(),  # 激活函数，引入非线性\n",
        "            nn.Linear(hidden_units_1, hidden_units_2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units_2, output_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 由于使用了nn.Sequential，forward函数变得极其简单\n",
        "        return self.layers(x)\n",
        "\n",
        "# 实例化模型\n",
        "model = RegressionNet()\n",
        "print(\"模型结构:\")\n",
        "print(model)\n",
        "\n",
        "# 创建一个假的输入数据 (batch_size=5, features=10)\n",
        "dummy_input = torch.randn(5, 10)\n",
        "\n",
        "# 将数据传入模型，得到输出\n",
        "output = model(dummy_input)\n",
        "\n",
        "print(f\"\\n输入形状: {dummy_input.shape}\")\n",
        "print(f\"输出形状: {output.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRoi-EBlFpyI",
        "outputId": "8af9cb3e-6c42-419c-954b-1667c9716ad6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型结构:\n",
            "RegressionNet(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "输入形状: torch.Size([5, 10])\n",
            "输出形状: torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89wiHNDCFp0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Colab单元格中运行\n",
        "\n",
        "# 实例化我们在Step 4中定义的模型\n",
        "model = RegressionNet()\n",
        "\n",
        "# 1. 定义损失函数\n",
        "# Mean Squared Error Loss，适用于回归问题\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# 2. 定义优化器\n",
        "# Adam优化器是一种非常流行的选择\n",
        "# 第一个参数 model.parameters() 告诉优化器需要更新哪些参数\n",
        "# lr (learning_rate) 是学习率，控制每次参数更新的步长\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "print(f\"损失函数: {loss_fn}\")\n",
        "print(f\"优化器: {optimizer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlSh4i33Fp3F",
        "outputId": "a792257b-fb46-4e98-d479-bde43517e937"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "损失函数: MSELoss()\n",
            "优化器: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6ka8GEVFp5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Colab单元格中运行\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# 1. 创建合成数据\n",
        "# 假设我们有1000个样本，每个样本有10个特征\n",
        "num_samples = 1000\n",
        "num_features = 10\n",
        "\n",
        "# X 是我们的特征 (随机生成)\n",
        "X = torch.randn(num_samples, num_features)\n",
        "\n",
        "# y 是我们的目标值 (假设是一个简单的线性关系加上一些噪声)\n",
        "true_weights = torch.tensor([0.5, -0.2, 1.5, -2.0, 0.8, -1.1, 0.3, -0.7, 1.2, -0.9])\n",
        "true_bias = 2.0\n",
        "y = X @ true_weights + true_bias + torch.randn(num_samples) * 0.1 # 矩阵乘法 + 偏置 + 噪声\n",
        "# y需要和模型输出的形状匹配，这里模型输出是(batch_size, 1)，所以我们reshape一下\n",
        "y = y.view(-1, 1)\n",
        "\n",
        "print(f\"特征数据形状: {X.shape}\")\n",
        "print(f\"标签数据形状: {y.shape}\\n\")\n",
        "\n",
        "# 2. 创建Dataset\n",
        "# TensorDataset将我们的特征和标签张量打包在一起\n",
        "dataset = TensorDataset(X, y)\n",
        "\n",
        "# 3. 创建DataLoader\n",
        "# BATCH_SIZE 决定了每次训练模型时使用多少个数据样本\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# shuffle=True 在每个epoch开始时都会打乱数据顺序，这对于训练非常重要\n",
        "# 它可以防止模型学到数据的特定顺序\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# 我们可以检查一下DataLoader的工作方式\n",
        "# 从data_loader中取出一个批次的数据\n",
        "features_batch, labels_batch = next(iter(data_loader))\n",
        "print(f\"从DataLoader取出的一个批次:\")\n",
        "print(f\"  特征批次形状: {features_batch.shape}\")\n",
        "print(f\"  标签批次形状: {labels_batch.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5QFGmIcFp7w",
        "outputId": "240bb6a1-eda1-4823-934c-53ad377b59bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特征数据形状: torch.Size([1000, 10])\n",
            "标签数据形状: torch.Size([1000, 1])\n",
            "\n",
            "从DataLoader取出的一个批次:\n",
            "  特征批次形状: torch.Size([32, 10])\n",
            "  标签批次形状: torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bWHzZCh9F8fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Colab单元格中运行\n",
        "\n",
        "# --- 准备工作 (从前面步骤复制代码) ---\n",
        "# 1. 模型\n",
        "model = RegressionNet()\n",
        "# 2. 损失函数\n",
        "loss_fn = nn.MSELoss()\n",
        "# 3. 优化器\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# 4. 数据加载器 (假设dataset和data_loader已在上一单元格创建)\n",
        "# data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# --- 训练循环 ---\n",
        "# epochs 是我们希望在整个数据集上训练的总轮数\n",
        "epochs = 10\n",
        "\n",
        "print(\"开始训练...\")\n",
        "\n",
        "# 外层循环遍历每一轮\n",
        "for epoch in range(epochs):\n",
        "    # 将模型设置为训练模式\n",
        "    model.train()\n",
        "\n",
        "    # 内层循环遍历DataLoader中的每一个批次\n",
        "    for batch, (X_batch, y_batch) in enumerate(data_loader):\n",
        "\n",
        "        # 1. 前向传播：计算预测值\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "        # 2. 计算损失\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "        # 3. 优化器三步舞\n",
        "        # 3.1 清空梯度\n",
        "        optimizer.zero_grad()\n",
        "        # 3.2 反向传播：计算梯度\n",
        "        loss.backward()\n",
        "        # 3.3 更新权重\n",
        "        optimizer.step()\n",
        "\n",
        "    # 在每轮训练结束后，打印损失信息\n",
        "    # 我们可以在评估模式下计算损失，这会关闭Dropout等层，但对于这个简单模型影响不大\n",
        "    model.eval()\n",
        "    with torch.no_grad(): # 在这个块中，不计算梯度，节省计算资源\n",
        "        y_pred_total = model(X) # 在整个数据集上进行预测\n",
        "        epoch_loss = loss_fn(y_pred_total, y)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss.item():.4f}\")\n",
        "\n",
        "print(\"\\n训练完成！\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbswS3P5F7_H",
        "outputId": "b0145745-b200-48e4-acb2-d8450f0cc4d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "开始训练...\n",
            "Epoch 1/10 | Loss: 11.4291\n",
            "Epoch 2/10 | Loss: 6.1704\n",
            "Epoch 3/10 | Loss: 1.6792\n",
            "Epoch 4/10 | Loss: 0.4714\n",
            "Epoch 5/10 | Loss: 0.3110\n",
            "Epoch 6/10 | Loss: 0.2277\n",
            "Epoch 7/10 | Loss: 0.1758\n",
            "Epoch 8/10 | Loss: 0.1404\n",
            "Epoch 9/10 | Loss: 0.1126\n",
            "Epoch 10/10 | Loss: 0.0945\n",
            "\n",
            "训练完成！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdnURjcBF8_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Colab单元格中运行\n",
        "\n",
        "# 1. 设置设备\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"正在使用的设备: {device}\\n\")\n",
        "\n",
        "# --- 准备工作 (GPU版本) ---\n",
        "# 1. 模型\n",
        "model_gpu = RegressionNet().to(device) # 将模型移动到GPU\n",
        "\n",
        "# 2. 损失函数 (损失函数通常不需要移动)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# 3. 优化器 (优化器会自动处理参数所在的设备)\n",
        "optimizer = torch.optim.Adam(model_gpu.parameters(), lr=0.001)\n",
        "\n",
        "# 4. 数据 (对于大型数据集，在训练循环中移动数据批次是最高效的)\n",
        "# X_gpu = X.to(device)\n",
        "# y_gpu = y.to(device)\n",
        "# dataset_gpu = TensorDataset(X_gpu, y_gpu)\n",
        "# data_loader_gpu = DataLoader(dataset_gpu, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# --- 训练循环 (GPU版本) ---\n",
        "epochs = 10\n",
        "print(\"开始在GPU上训练...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model_gpu.train()\n",
        "    for X_batch, y_batch in data_loader:\n",
        "        # !! 关键步骤: 将数据批次移动到GPU !!\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        y_pred = model_gpu(X_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # 打印损失\n",
        "    model_gpu.eval()\n",
        "    with torch.no_grad():\n",
        "        # 将整个数据集移动到GPU进行评估\n",
        "        epoch_loss = loss_fn(model_gpu(X.to(device)), y.to(device))\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss.item():.4f}\")\n",
        "\n",
        "print(\"\\n训练完成！\")\n",
        "\n",
        "\n",
        "# --- 5. 保存和加载模型 ---\n",
        "\n",
        "# 定义模型保存路径\n",
        "MODEL_PATH = \"regression_model.pth\"\n",
        "\n",
        "# 保存模型的状态字典\n",
        "print(f\"\\n正在保存模型到: {MODEL_PATH}\")\n",
        "torch.save(obj=model_gpu.state_dict(), f=MODEL_PATH)\n",
        "\n",
        "# 加载模型\n",
        "# 1. 创建一个新的、未经训练的模型实例\n",
        "loaded_model = RegressionNet()\n",
        "\n",
        "# 2. 加载已保存的状态字典\n",
        "# 注意：加载前，模型需要知道参数应该在哪个设备上\n",
        "# 我们先加载到CPU，然后再移动到目标设备\n",
        "loaded_model.load_state_dict(torch.load(f=MODEL_PATH))\n",
        "\n",
        "# 3. 将加载的模型移动到目标设备\n",
        "loaded_model.to(device)\n",
        "\n",
        "# 4. 测试加载的模型\n",
        "loaded_model.eval()\n",
        "with torch.no_grad():\n",
        "    # 使用加载的模型进行预测\n",
        "    sample_input = torch.randn(1, 10).to(device)\n",
        "    prediction = loaded_model(sample_input)\n",
        "    print(f\"\\n使用加载的模型进行预测:\")\n",
        "    print(f\"输入: {sample_input.cpu().numpy()}\")\n",
        "    print(f\"预测输出: {prediction.cpu().numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPFiDc2YF9Qr",
        "outputId": "790f0d25-2ec3-4567-c65f-205236ecf326"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在使用的设备: cuda\n",
            "\n",
            "开始在GPU上训练...\n",
            "Epoch 1/10 | Loss: 12.5242\n",
            "Epoch 2/10 | Loss: 6.5093\n",
            "Epoch 3/10 | Loss: 1.1389\n",
            "Epoch 4/10 | Loss: 0.2795\n",
            "Epoch 5/10 | Loss: 0.1995\n",
            "Epoch 6/10 | Loss: 0.1511\n",
            "Epoch 7/10 | Loss: 0.1188\n",
            "Epoch 8/10 | Loss: 0.0986\n",
            "Epoch 9/10 | Loss: 0.0820\n",
            "Epoch 10/10 | Loss: 0.0687\n",
            "\n",
            "训练完成！\n",
            "\n",
            "正在保存模型到: regression_model.pth\n",
            "\n",
            "使用加载的模型进行预测:\n",
            "输入: [[-0.10295513  0.4530604  -1.9070609   0.12943898 -0.07786548 -0.5137562\n",
            "   1.0706341  -0.99571174  0.15195853 -0.9119981 ]]\n",
            "预测输出: [[1.3044779]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9c07taTGF9eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jy_XV49DF98Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LXIGLYhwF9_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Colab单元格中运行\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm # 用于显示漂亮的进度条\n",
        "\n",
        "# 1. 下载数据集\n",
        "# a wget command to download the dataset\n",
        "!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "\n",
        "# 2. 解压数据集\n",
        "with zipfile.ZipFile(\"hymenoptera_data.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "# 3. 定义数据路径\n",
        "data_dir = \"hymenoptera_data\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "val_dir = os.path.join(data_dir, \"val\")\n",
        "\n",
        "print(f\"训练数据目录: {train_dir}\")\n",
        "print(f\"验证数据目录: {val_dir}\")\n",
        "# 你可以看到目录下已经分好了 'ants' 和 'bees' 两个文件夹\n",
        "print(f\"训练集中的类别: {os.listdir(train_dir)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7vA7_DPF-B9",
        "outputId": "6c17486d-d3bd-409a-9f6c-498fd71a91d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-09 15:33:33--  https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 99.84.215.85, 99.84.215.59, 99.84.215.76, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|99.84.215.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47286322 (45M) [application/zip]\n",
            "Saving to: ‘hymenoptera_data.zip’\n",
            "\n",
            "hymenoptera_data.zi 100%[===================>]  45.10M   226MB/s    in 0.2s    \n",
            "\n",
            "2025-09-09 15:33:33 (226 MB/s) - ‘hymenoptera_data.zip’ saved [47286322/47286322]\n",
            "\n",
            "训练数据目录: hymenoptera_data/train\n",
            "验证数据目录: hymenoptera_data/val\n",
            "训练集中的类别: ['bees', 'ants']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jED5GhipF-Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Colab单元格中运行\n",
        "\n",
        "# 1. 定义数据预处理和增强\n",
        "# 对训练集和验证集使用不同的变换\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224), # 随机裁剪到224x224\n",
        "        transforms.RandomHorizontalFlip(), # 随机水平翻转\n",
        "        transforms.ToTensor(), # 转换为Tensor\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 标准化\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256), # 缩放到256\n",
        "        transforms.CenterCrop(224), # 中心裁剪到224x224\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# 2. 使用 ImageFolder 创建 Datasets\n",
        "# ImageFolder 是一个神奇的工具，它会自动从文件夹结构中读取图片和标签\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "# 3. 创建 DataLoaders\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=2)\n",
        "               for x in ['train', 'val']}\n",
        "\n",
        "# 4. 获取数据集大小和类别名称\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(f\"数据集大小: {dataset_sizes}\")\n",
        "print(f\"类别: {class_names}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCwTuigCF-G_",
        "outputId": "97672cd6-acd6-4ec1-945d-d0d24cab684f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据集大小: {'train': 244, 'val': 153}\n",
            "类别: ['ants', 'bees']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oUcnGxgHccM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Colab单元格中运行\n",
        "\n",
        "# 1. 加载预训练的ResNet-18模型\n",
        "# weights=models.ResNet18_Weights.DEFAULT 是当前推荐的加载最新预训练权重的方法\n",
        "model_ft = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# 2. 冻结所有基础层参数\n",
        "# 我们不希望在初始训练时破坏预训练模型已经学到的特征\n",
        "for param in model_ft.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 3. 修改分类器 (最后一层)\n",
        "# ResNet-18的最后一层是一个名为 `fc` 的全连接层\n",
        "num_ftrs = model_ft.fc.in_features # 获取原始最后一层的输入特征数\n",
        "# 将其替换为一个新的全连接层，输出我们需要的类别数 (蚂蚁 vs 蜜蜂 -> 2)\n",
        "# 注意：新创建的层的参数默认 requires_grad=True\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "# 4. 将模型移动到GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "print(\"修改后的模型结构 (只看最后几层):\")\n",
        "print(model_ft)\n",
        "\n",
        "# 5. 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 只优化我们修改过的分类器层的参数\n",
        "optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJyzovfGHcZn",
        "outputId": "03f9f4c9-66a1-4666-9db4-4f9e1b71a6ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 179MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "修改后的模型结构 (只看最后几层):\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gQdnDK7SHcXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Colab单元格中运行\n",
        "\n",
        "# --- 训练循环 ---\n",
        "epochs = 15\n",
        "print(\"\\n开始微调训练...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch+1}/{epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    # 每个epoch都有一个训练和验证阶段\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model_ft.train()  # 设置模型为训练模式\n",
        "        else:\n",
        "            model_ft.eval()   # 设置模型为评估模式\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # 迭代数据\n",
        "        for inputs, labels in tqdm(dataloaders[phase], desc=phase):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 梯度清零\n",
        "            optimizer_ft.zero_grad()\n",
        "\n",
        "            # 只在训练阶段进行前向传播和反向传播\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model_ft(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # 如果是训练阶段，则执行反向传播 + 优化\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer_ft.step()\n",
        "\n",
        "            # 统计损失和准确率\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\\n')\n",
        "\n",
        "print(\"微调完成！\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qph0E8GTHcU2",
        "outputId": "9104eff1-e6a2-4174-a583-8c0ff00f8c36"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "开始微调训练...\n",
            "Epoch 1/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:03<00:00, 17.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.2662 Acc: 0.5656\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:00<00:00, 39.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.7826 Acc: 0.6536\n",
            "\n",
            "Epoch 2/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 49.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5989 Acc: 0.7459\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:01<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.2087 Acc: 0.9346\n",
            "\n",
            "Epoch 3/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 49.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4905 Acc: 0.8279\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:00<00:00, 39.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.2472 Acc: 0.9020\n",
            "\n",
            "Epoch 4/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 38.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.6104 Acc: 0.7582\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:01<00:00, 24.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.2143 Acc: 0.9412\n",
            "\n",
            "Epoch 5/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 47.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4771 Acc: 0.8156\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:00<00:00, 39.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.1588 Acc: 0.9608\n",
            "\n",
            "Epoch 6/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 48.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5050 Acc: 0.7910\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:00<00:00, 39.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.1954 Acc: 0.9346\n",
            "\n",
            "Epoch 7/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 48.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3936 Acc: 0.8156\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:00<00:00, 39.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.2443 Acc: 0.9085\n",
            "\n",
            "Epoch 8/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 49.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4492 Acc: 0.8156\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:00<00:00, 40.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.1605 Acc: 0.9608\n",
            "\n",
            "Epoch 9/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 44.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4061 Acc: 0.8443\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:01<00:00, 20.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.1804 Acc: 0.9346\n",
            "\n",
            "Epoch 10/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:02<00:00, 26.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5158 Acc: 0.7910\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:01<00:00, 38.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4425 Acc: 0.8366\n",
            "\n",
            "Epoch 11/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 48.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.6047 Acc: 0.7459\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:00<00:00, 39.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3410 Acc: 0.8824\n",
            "\n",
            "Epoch 12/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 48.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5398 Acc: 0.7746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:00<00:00, 40.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4665 Acc: 0.8431\n",
            "\n",
            "Epoch 13/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 49.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5728 Acc: 0.7869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:00<00:00, 39.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3333 Acc: 0.8954\n",
            "\n",
            "Epoch 14/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 32.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5246 Acc: 0.8156\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:01<00:00, 26.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.2527 Acc: 0.9346\n",
            "\n",
            "Epoch 15/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 61/61 [00:01<00:00, 48.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3857 Acc: 0.8279\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 39/39 [00:01<00:00, 38.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.2431 Acc: 0.9281\n",
            "\n",
            "微调完成！\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MyT8c2rSHcSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0SpzO0LHcPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiaCmZ7dHcLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9xefaDwHcEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fZ6_O1MOHb0Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}